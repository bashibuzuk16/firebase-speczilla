# -*- coding: utf-8 -*-
import os
import re
import base64
import json
import fitz  # PyMuPDF
import time
import asyncio
import aiohttp
import traceback  # Для вывода полного стека ошибок
import openpyxl  # Для работы с файлами XLSX
from openpyxl.workbook import Workbook
from datetime import datetime  # Для форматирования времени
from typing import Union, List, Dict, Tuple, Any  # Уточненные импорты
import ast  # Добавлен импорт для ast.literal_eval
import sys

# Конфигурация

# Список ключей Gemini
# ВНИМАНИЕ: Замените эти ключи на ваши реальные ключи API Gemini.
GEMINI_API_KEYS = [
    "AIzaSyALIzqQk6hF4fkazirMYpSXwP3okNwY0dw",  # Замените на ваш первый ключ
    "AIzaSyDIm86XqVOZ-l-kvK9UlAW1qyD2LrcOmLs",  # Замените на ваш второй ключ
    "AIzaSyCfuUYzs-ejaqgvjGaxhiL7Ts7rFQ2yN70",  # Замените на ваш третий ключ
]

if not GEMINI_API_KEYS or GEMINI_API_KEYS == ["dummy_key_for_empty_list"] or any("Замените на ваш" in key for key in GEMINI_API_KEYS):
    print("ОШИБКА: Список ключей GEMINI_API_KEYS пуст или содержит заглушки. Добавьте реальные ключи.")
    # Для продолжения работы в тестовом режиме, если ключи не установлены, можно использовать заглушку.
    # В реальной ситуации здесь следует прервать выполнение или запросить ключи.
    GEMINI_API_KEYS = ["dummy_fallback_key_if_not_set"] # Эта заглушка не будет работать, но позволит коду не падать сразу

gemini_key_index_counter = 0
gemini_key_index_lock = asyncio.Lock()

# Ограничения на количество одновременных задач
CONCURRENT_STAGE_1_PAGE_ID_LIMIT = 1
CONCURRENT_STAGE_2_EXTRACTION_LIMIT = 9
CONCURRENT_STAGE_3_ARTICLE_LIMIT = 1  # Этап 3 обрабатывается последовательно из-за зависимости от previous_datatable
CONCURRENT_STAGE_4_RAG_TEXT_LIMIT = 9
CONCURRENT_STAGE_5_DETAIL_ATTR_LIMIT = 9
CONCURRENT_STAGE_6_MATCHING_LIMIT = 5
CONCURRENT_STAGE_7_PAGE_SEARCH_LIMIT = 3 # Новый лимит для Этапа 7

# Путь к файлу справочника артикулов для Этапа 6
REFERENCE_ARTICLES_FILE_PATH = r"C:\Users\anvar\OneDrive\Desktop\спецификации\Отопление\соотнесение артикулов _ready_to_embed.txt"

# --- Этап 1: Определение релевантных страниц (весь документ) ---
WHOLE_DOC_SPEC_PAGE_IDENTIFICATION_SYSTEM_INSTRUCTION = """Инструкция по поиску табличных данных (спецификаций) в PDF-документах

Цель: Найти в PDF-документах таблицы, содержащие перечни оборудования или материалов с характеристиками, аналогичные предоставленному образцу.

Шаг 1: Анализ образца и определение ключевых признаков

Прежде чем начать поиск, внимательно изучите предоставленное изображение таблицы и выделите ее характерные черты:

Основные заголовки столбцов:
"Позиция" (или "№ п/п", "Поз.")
"Наименование и техническая характеристика" (или "Описание", "Наименование изделия")
"Тип, марка, обозначение документа и опросного листа" (или "Артикул", "Модель", "Код")
"Код оборудования, изделия, материала"
"Завод изготовитель" (или "Производитель")
"Ед. измерения" (или "Ед. изм.")
"Количество" (или "Кол-во")
"Масса" (или "Вес")
"Примечание"
Подумайте о возможных вариациях этих заголовков.
Типы данных в столбцах:
Позиция: Числа, возможно с точками (1.1, 1.2).
Наименование: Длинный описательный текст.
Тип/Марка/Код: Буквенно-цифровые строки, часто с дефисами, слешами, точками.
Завод изготовитель: Названия компаний (часто в кавычках или заглавными буквами).
Ед. измерения: Краткие сокращения ("шт.", "компл.", "м").
Количество/Масса: Целые или десятичные числа.
Общая структура: Многоколоночная таблица, строки с данными разделены (визуально или логически).
Характерные ключевые слова (помимо заголовков): Слова, часто встречающиеся в таких таблицах, например, "щит", "контроллер", "модуль", "кабель", "выключатель", "датчик", "ГОСТ", "ТУ", "спецификация", "перечень", "ведомость".
Контекст: Такие таблицы обычно являются частью проектной документации, технических описаний, каталогов продукции.
Шаг 2: Подготовка PDF-документов и инструментов

Доступность текста: Убедитесь, что PDF-документы содержат распознанный текст, а не являются просто отсканированными изображениями. Если PDF – это изображение, для поиска по тексту потребуется предварительное Оптическое Распознавание Символов (OCR). Многие PDF-просмотрщики и редакторы имеют встроенную функцию OCR или могут работать с уже распознанными документами.
Инструменты:
Стандартный PDF-просмотрщик (Adobe Acrobat Reader, Foxit Reader и т.д.) с функцией поиска (обычно Ctrl+F или Cmd+F).
Продвинутые PDF-редакторы (Adobe Acrobat Pro, Foxit PDF Editor Pro) могут предлагать более сложные опции поиска, включая поиск по нескольким словам, учет регистра и т.д.
(Опционально) Специализированные программы для извлечения данных из PDF: Инструменты вроде Tabula (бесплатный), Abbyy FineReader (с функциями экспорта таблиц), или библиотеки для языков программирования (например, pdfplumber или camelot для Python) могут помочь не только найти, но и извлечь таблицы. Это актуально для больших объемов данных.
Шаг 3: Стратегии поиска

А. Поиск по ключевым словам (наиболее распространенный метод):

Используйте заголовки столбцов: Начните с поиска наиболее уникальных и стабильных заголовков из Шага 1. Например:
"Завод изготовитель"
"Ед. измерения"
"Код оборудования"
"Техническая характеристика"
Используйте комбинации ключевых слов: Если возможно, ищите несколько слов, которые вероятно появятся рядом. Например, "Наименование" и "Количество" на одной странице.
Ищите общие термины для спецификаций:
"Спецификация"
"Перечень оборудования"
"Ведомость комплектации"
"Номенклатура"
Ищите характерные значения из ячеек: Если вы знаете типичные единицы измерения ("шт.") или часто встречающихся производителей ("ОВЕН", "IEK" – из примера), попробуйте искать их. Это может помочь быстро перейти к нужным разделам.
Пробуйте вариации: Учитывайте возможные синонимы, сокращения или разные падежи слов.
Б. Визуальный просмотр и анализ структуры:

Быстрое сканирование: Пролистывайте документ, обращая внимание на страницы с явной табличной версткой (сетка, колонки текста).
Ориентируйтесь на плотность информации: Таблицы спецификаций часто содержат много текста и цифр, сгруппированных в столбцы.
Ищите повторяющиеся шаблоны: Например, столбец с короткими числовыми позициями, за которым следует столбец с длинным описанием.
Шаг 4: Проверка и уточнение найденного

Сравнение с образцом: Как только вы нашли потенциальную таблицу, сравните ее структуру и заголовки столбцов с вашим образцом (изображением).
Анализ содержимого: Проверьте, соответствуют ли данные в столбцах ожидаемым типам (текст, числа, коды).
Оценка релевантности: Убедитесь, что найденная таблица действительно относится к тому типу информации, который вы ищете (например, это спецификация оборудования, а не финансовый отчет с похожей структурой).
Контекст документа: Обратите внимание на название документа или раздела, где найдена таблица, чтобы подтвердить ее назначение.
"""
WHOLE_DOC_SPEC_PAGE_IDENTIFICATION_RESPONSE_SCHEMA = {
    "type": "object", "properties": {"relevant_pages": {"type": "array", "items": {"type": "integer"}}},
    "required": ["relevant_pages"]
}

STAGE_1_USER_PROMPT_TEXT = """Инструкция для AI-помощника по поиску страниц со спецификациями в PDF
Цель
Найти все страницы в PDF-документе, содержащие структурированные данные (таблицы, списки, технические параметры), и вернуть их номера в формате JSON. Номера страниц должны быть 1-индексированными.
Шаги выполнения
Определение критериев структурированных данных
Таблицы: Наличие колонок, строк, разделителей (например, |, ---), заголовков столбцов.
Списки: Маркированные/нумерованные пункты, элементы с префиксами (•, -, 1., 2.).
Ключевые слова:
"Спецификация", "Параметры", "Технические характеристики", "Характеристики", "Модель", "Размеры".
Словари единиц измерения: мм, кг, Вт, В, Гц и т.п.
Структура: Заголовки с подзаголовками, повторяющиеся шаблоны данных (например, Параметр: значение).
Анализ документа
Разделить PDF на отдельные страницы.
Для каждой страницы:
Извлечь текст с сохранением структуры (таблицы, списки, абзацы).
Искать элементы из п. 1 (таблицы, списки, ключевые слова, единицы измерения).
Если на странице найдено ≥2 признаков структурированных данных — добавить её номер (1-индексированный) в результат.
Фильтрация ложных срабатываний
Игнорировать страницы:
С сплошным текстом без разделения на элементы.
Где таблицы/списки содержат не технические данные (например, оглавление, библиография).
Формирование JSON
Вывести номера страниц (1-индексированные) в виде массива, даже если найдена одна подходящая страница.
Пример корректного формата:
```json
{
"relevant_pages": [5, 12, 17]
}
```
Важно
Если спецификации разбиты на несколько страниц — указать все связанные номера.
Не включать титульные листы, содержание, приложения без структурированных данных."""

# --- Этап 2: Извлечение первичных данных (Datatable) ---
STAGE_2_EXTRACTION_SYSTEM_INSTRUCTION = """
**Роль:** Ты - система интеллектуальной обработки данных спецификаций, извлекающая табличные данные из PDF документов. Любое отклонение от инструкций приведет к поломке работы дальнейших алгоритмов.

**Задача:** Проанализировать предоставленную страницу PDF и извлечь табличные данные, соответствующие следующим столбцам:
- поз (номер позиции)
- Наименование и техническая характеристика
- Тип, марка, обозначение документа, опросного листа
- Код продукции
- Поставщик
- Ед. измерения
- Количество
- Масса 1 ед., кг
- Примечание

**Требования:**
- Итоговый вывод должен быть _исключительно корректным JSON массивом_ (начинающимся с `[` и заканчивающимся `]`). Никакого дополнительного текста или отладочной информации!
- Каждый элемент массива должен быть JSON объектом, представляющим одну строку таблицы.
- Используй точные наименования полей в JSON, как указано в списке столбцов выше (на русском языке, включая пробелы и знаки препинания, как в списке).
- Если какие-то данные отсутствуют в строке таблицы, оставь соответствующее поле в JSON объекте пустым (пустая строка "").
- Все извлеченные значения должны быть строками.

**Пример ожидаемого результата (структура):**
```json
[
  {
    "поз": "1",
    "Наименование и техническая характеристика": "Пример наименования",
    "Тип, марка, обозначение документа, опросного листа": "Пример типа",
    "Код продукции": "Пример кода",
    "Поставщик": "Пример поставщика",
    "Ед. измерения": "шт",
    "Количество": "10",
    "Масса 1 ед., кг": "0.5",
    "Примечание": ""
  },
  {
    "поз": "2",
    "Наименование и техническая характеристика": "Другое наименование",
    "Тип, марка, обозначение документа, опросного листа": "",
    "Код продукции": "",
    "Поставщик": "Другой поставщик",
    "Ед. измерения": "м",
    "Количество": "100",
    "Масса 1 ед., кг": "2.1",
    "Примечание": "Важное примечание"
  }
]
```
Обработай входной PDF согласно этим правилам и выведи результат только в формате корректного JSON массива.
"""

# --- Этап 3: Заполнение поля 'article' ---
STAGE_3_ARTICLE_FILLING_SYSTEM_INSTRUCTION = """
**Роль:** Ты - система интеллектуальной обработки данных спецификаций для заполнения описательного поля 'article' в составе автоматизированной системы обработки данных. Любое отклонение от инструкций приведет к поломке работы дальнейших алгоритмов.

**Задача:** Обработать входящий JSON, содержащий список компонентов из проектной документации для текущей страницы (`datatable`) и, если доступно, список компонентов с предыдущей страницы (`previous_datatable`). Для каждого компонента в `datatable` необходимо проанализировать поле `name` и, при необходимости, использовать данные из `previous_datatable` или предыдущих элементов в `datatable` для формирования и записи соответствующего значения в поле `article` этого компонента. Результатом должен быть JSON, содержащий только обновленный `datatable` для текущей страницы.

**Входные данные:**
Структура представляет собой JSON объект с двумя ключами:
- `"datatable"`: Массив объектов компонентов для текущей страницы.
- `"previous_datatable"`: Массив объектов компонентов с предыдущей страницы. Этот ключ может отсутствовать или быть пустым, если это первая страница или нет данных с предыдущей.

**Требования:**
- Итоговый вывод должен быть _исключительно корректным JSON_ (начинающимся с `{` и заканчивающимся `}`). Никакого дополнительного текста или отладочной информации!
- **ВАЖНО:** Итоговый JSON должен содержать _только_ ключ `"datatable"` с обновленными данными для текущей страницы. Не включай `"previous_datatable"` в выходной JSON.
- Все поля (включая числовые) должны оставаться строками. Не выполнять никаких вычислений и не применять функцию конвертации, которая приводит к появлению вида «string(0.0000...)».
- Поле `article` формируется по следующему правилу:
  - Проанализируй `name` текущего компонента.
  - Если `name` содержит полное описание компонента (например, "Хомут сантехнический с резиновым уплотнителем для трубы: Ду 15"), сформируй `article` в формате: `"<Основное_наименование><материал><размер>"`.
  - Если `name` содержит лишь часть описания (например, только размер "Ду50" или "Ду65"), это, вероятно, продолжение списка однотипных компонентов, начатого на предыдущей странице или ранее на текущей.
  - **Для таких неполных описаний:**
    - **Сначала ищи базовое описание в `previous_datatable`:** Просмотри элементы в `previous_datatable` в обратном порядке (с конца к началу). Найди последний элемент, чье поле `name` содержит полное описание или является "заголовком" для серии компонентов (например, "Хомут сантехнический с резиновым уплотнителем для трубы:").
    - **Если базовое описание найдено в `previous_datatable`:** Используй это базовое описание и объедини его с информацией (например, размером) из `name` текущего компонента.
    - **Если базовое описание не найдено в `previous_datatable`:** Ищи базовое описание в `datatable` (текущей странице) в обратном порядке до текущего элемента.
    - **Если базовое описание найдено в `datatable`:** Используй это базовое описание и объедини его с информацией из `name` текущего компонента.
    - **Если базовое описание не найдено нигде:** Используй только информацию из `name` текущего компонента для `article`.

  **Коррекция символа диаметра:** При формировании поля `article`, если в поле `name` встречаются символы "Ф", "$", "ф", "Ду" или фразы "диаметром" в контексте размеров (например, рядом с числами), интерпретируй их как символ диаметра "Ø" и используй именно "Ø" в поле `article`. Например, "диаметром 20" -> "Ø 20", "Ду 15" -> "Ø 15".

- Структура элементов в выходном `datatable` должна соответствовать входной, без изменений ключей и регистров, кроме заполненного поля `article`.

**Пример входных данных (для страницы, следующей за страницей с полным описанием):**
```json
{
  "datatable": [
    {
      "pos": "", "name": "Ду50", "type": "", "code": "", "manufacturer": "", "measure": "шт.", "quantity": "34", "weight": "", "note": "", "article": ""
    },
    {
      "pos": "", "name": "Ду65", "type": "", "code": "", "manufacturer": "", "measure": "шт.", "quantity": "3", "weight": "", "note": "", "article": ""
    }
  ],
  "previous_datatable": [
    {
      "pos": "62", "name": "Хомут сантехнический с резиновым уплотнителем для трубы:", "type": "", "code": "", "manufacturer": "", "measure": "", "quantity": "", "weight": "", "note": "", "article": "[Хомут сантехнический][][Ду 15 ]"
    },
    {
      "pos": "63", "name": "Ду 15", "type": "", "code": "", "manufacturer": "", "measure": "шт.", "quantity": "131", "weight": "", "note": "", "article": "[Хомут сантехнический][][Ду 15 ]"
    }
  ]
}
```

**Пример ожидаемого результата (для входных данных выше):**
```json
{
  "datatable": [
    {
      "pos": "", "name": "Ду50", "type": "", "code": "", "manufacturer": "", "measure": "шт.", "quantity": "34", "weight": "", "note": "", "article": "[Хомут сантехнический][резина][Ø 50]"
    },
    {
      "pos": "", "name": "Ду65", "type": "", "code": "", "manufacturer": "", "measure": "шт.", "quantity": "3", "weight": "", "note": "", "article": "[Хомут сантехнический][резина][Ø 65]"
    }
  ]
}
```
Обработай входной JSON согласно этим правилам и выведи результат только в формате корректного JSON, содержащего только обновленный `datatable` для текущей страницы.
"""
STAGE_3_ARTICLE_FILLING_RESPONSE_SCHEMA = {
    "type": "object", "properties": {"datatable": {"type": "array", "items": {
        "type": "object", "properties": {
            "pos": {"type": "string"}, "name": {"type": "string"}, "type": {"type": "string"},
            "code": {"type": "string"}, "manufacturer": {"type": "string"}, "measure": {"type": "string"},
            "quantity": {"type": "string"}, "weight": {"type": "string"}, "note": {"type": "string"},
            "article": {"type": "string"}
        },
        "required": ["pos", "name", "type", "code", "manufacturer", "measure", "quantity", "weight", "note", "article"]
    }}}, "required": ["datatable"]
}

# --- Этап 4: Заполнение поля 'rag_text' ---
STAGE_4_RAG_TEXT_SYSTEM_INSTRUCTION = """
Роль: Ты - эксперт по обработке и нормализации текстовых данных, связанных с оборудованием и материалами для систем канализации, отопления и водоснабжения. Твоя задача - подготовить эти данные для последующего сопоставления, создавая максимально развернутое и при этом стандартизированное представление наименования товара в поле `rag_text`, используя как поле "name", так и существующее поле "article".

Задача: Получить на вход массив JSON, где каждый элемент представляет собой объект с данными о товаре. Необходимо проанализировать поле "name" каждого объекта, используя, если необходимо, информацию из поля "article", чтобы получить максимально полное, очищенное и стандартизированное представление наименования товара. Результат обработки каждого "name" должен быть записан в новое поле "rag_text" в том же объекте.

Входные Данные:
[
    {
        "article": "[Капельная воронка][][DN32]",
        "code": "",
        "manufacturer": "HL Hutterer & Lechner GmbH",
        "measure": "шт.",
        "name": "Капельная воронка DN32 с запахозапирающим устройством",
        "note": "",
        "pos": "",
        "quantity": "40",
        "type": "",
        "weight": ""
    },
    {
        "article": "[Патрубок переходной канализационный][полипропилен][DN50x32]",
        "code": "",
        "manufacturer": "",
        "measure": "шт.",
        "name": "Патрубок переходной канализационный малошумный из полипропилена концентрический, DN50x32",
        "note": "",
        "pos": "",
        "quantity": "40",
        "type": "",
        "weight": ""
    },
    {
        "article": "[Труба канализационная раструбная][ПП][Ø32 мм]",
        "code": "",
        "manufacturer": "",
        "measure": "М.",
        "name": "Труба канализационная раструбная ПП Ø32 мм",
        "note": "",
        "pos": "",
        "quantity": "0.26",
        "type": "",
        "weight": ""
    },
     {
        "article": "[Труба стальная][][Ø 15]",
        "code": "",
        "manufacturer": "",
        "measure": "M",
        "name": "Труба 15х2,8 (Дн 21,3 мм)",
        "note": "",
        "pos": "",
        "quantity": "141.6",
        "rag_text": "",
        "type": "",
        "weight": ""
    },
     {
        "article": "[Труба РЕ-Ха/EVOH][][16x2,2]",
        "code": "",
        "manufacturer": "По бренд-листу",
        "measure": "м",
        "name": "Труба РЕ-Ха/EVOH SDR 7.4/S 3.2 16x2,2",
        "note": "",
        "pos": "",
        "quantity": "370.2",
        "rag_text": "",
        "type": ""
    }
]

JSON массив, где каждый объект имеет ключи "name" (строка с наименованием товара) и "article" (строка с дополнительной информацией о товаре, обычно в формате `[Основное_Наименование][Материал][Основной_Размер]`). Другие поля (например, "pos", "type" (являющееся `type_original` из предыдущих этапов) и т.д.) не нужно изменять.

Выходные Данные (пример для последней входной записи):
[
    // ... предыдущие записи
     {
        "article": "[Труба РЕ-Ха/EVOH][][16x2,2]",
        "code": "",
        "manufacturer": "По бренд-листу",
        "measure": "м",
        "name": "Труба РЕ-Ха/EVOH SDR 7.4/S 3.2 16x2,2",
        "note": "",
        "pos": "",
        "quantity": "370.2",
        "type": "",
        "rag_text": "труба ре-ха/evoh sdr 7.4 s 3.2 размер 16x2.2 материал pe-xa evoh назначение для систем водоснабжения/отопления категория трубы"
    }
]

JSON массив, структура которого полностью соответствует входному массиву, но при этом поле "rag_text" каждого объекта должно быть обработано согласно инструкциям ниже. Поля "name" и "article", а также все остальные поля из входного объекта, не изменяются и должны присутствовать в выходном объекте.

Инструкции по Обработке Поля "name" (для формирования "rag_text"):

**Цель:** Создать максимально развернутое, очищенное и стандартизированное текстовое представление товара в поле `rag_text`. Этот текст должен служить богатым источником информации для последующего извлечения ключевых атрибутов, таких как тип изделия, размер, материал, категория, функция, типы соединений и возможные синонимы (allies), необходимых для точного сопоставления с эталонными данными.

Использование Поля "article" как Контекста/Базы:
- Используй информацию из поля "article" (основное наименование, материал, основной размер) как базовые элементы для включения в "rag_text", особенно если они отсутствуют или менее четко выражены в "name".
- **Комбинируй информацию:** Объединяй ключевую информацию из "article" с деталями из "name". Не заменяй информацию из "name" полностью на "article", а дополняй и обогащай.

Удаление лишней информации:
- Удалить единицы измерения (например, "кг", "м", если они есть), кроме тех, что относятся непосредственно к размерам (например, "мм", "см", "дюйм").
- Удалить явно избыточные или малоинформативные описательные слова, которые не несут уникальной характеристики товара в контексте сопоставления (например, "стандартнопроходной", "для трубы", "с резиновым уплотнителем", если основное наименование уже включает суть). Используй "article" для определения основного наименования и материала, чтобы понять, какие описания в "name" могут быть избыточными.
- Удалить лишние пробелы (оставляя одиночные между словами).

Форматирование:
- Привести все символы в "rag_text" к нижнему регистру.
- Заменить "Ф", "$", "ф", "Ду", "Дн" и фразы типа "диаметром" на "Ø" в контексте числовых размеров.
- Сохранять сокращения типа "ВР/ВР" (внутренняя резьба / внутренняя резьба) без разделения, если они являются устоявшимися обозначениями.
- Заменить дроби на десятичные значения (например, 1/2 на 0.5, 3/4 на 0.75, 1 1/2 на 1.5). Обрабатывать случаи, когда целая часть и дробь разделены пробелом.
- Разделять размеры, если они записаны слитно (например, "500х80" -> "500 х 80").
- **Сохранять все найденные размерности:** Включать в "rag_text" все числовые размерности, найденные в "name" (например, "15х2,8" и "Дн 21,3 мм" из "Труба 15х2,8 (Дн 21,3 мм)" должны быть преобразованы и включены как "размер 15х2.8 ø 21.3 мм").
- **Стандартизировать и включать технические аббревиатуры:** Включать в "rag_text" такие технические аббревиатуры и обозначения, как типы материалов (PE-Xa, PE-Xb, PE-Xc, EVOH, PPR, PVC, ПП, ПЭ и т.п.), стандарты (SDR, PN), серии (S), а также их числовые значения, приводя их к нижнему регистру и сохраняя связь с числами (например, "SDR 7.4" -> "sdr 7.4", "S 3.2" -> "s 3.2", "PE-Xa/EVOH" -> "ре-ха/evoh" или "pe-xa/evoh").

Сохранение и Явное Включение Ключевой Информации:
- **Основное наименование товара:** Включить из "article" или "name". Это соответствует понятию "тип изделия".
- **Материал изделия:** Включить из "article" или "name". Если материалов несколько, перечислить их.
- **Размеры:** Включать ВСЕ найденные размерности и технические обозначения (диаметр, длина, высота, толщина, количество секций, SDR, S-серия и т.п.) из "name", стандартизируя их согласно правилам выше. Использовать префикс "размер" или аналогичный для ясности, например, "размер ø15х2.8 мм".
- **Категория товара:** Если из `name` или `article` можно определить общую категорию товара (например, "арматура", "трубы", "фитинги", "насос", "радиатор", "теплоизоляция"), включите эту информацию, например, "категория фитинги".
- **Функциональное назначение:** Если из `name` или `article` можно определить основное назначение или функцию товара (например, "для систем отопления", "регулирующий", "запорный", "для транспортировки холодной воды", "изменение направления потока"), включите эту информацию в стандартизированной форме, например, "назначение регулирование потока".
- **Типы соединений:** Если в `name` или `article` указаны типы соединений (например, "резьбовой", "фланцевый", "под приварку", "раструбный", "НР/ВР"), включите их, по возможности стандартизируя и указывая размеры, если они есть (например, "соединение резьбовое G1/2 нр", "соединение под сварку", "соединение раструбное ø50 мм").
- **Возможные синонимы/связанные термины (allies):** Если для основного наименования товара существуют общепринятые синонимы или близкие по смыслу термины, которые могут помочь в сопоставлении (например, для "отвод" -> "колено"; для "термостатический элемент" -> "термоголовка", "терморегулятор"), кратко укажите их, например, "allies колено".
- **Другая важная техническая информация:** Включать другую важную техническую информацию из "name", которая не является избыточной по сравнению с информацией, взятой из "article", и может быть полезна для сопоставления (например, рабочее давление, класс прочности, цвет, если он является отличительной характеристикой).

Важные Примечания:
- Выполняй обработку последовательно, шаг за шагом.
- "name" - основной источник деталей. "article" (в его структурированном виде `[Наименование][Материал][Размер]`) - источник стандартизированных ключевых элементов и контекста.
- **Цель `rag_text`:** Максимально полное и структурированное (в рамках строки) представление товара в стандартизированном формате для последующего легкого извлечения атрибутов и точного поиска/сопоставления.
- Обрабатывай каждый элемент массива независимо.
- Выводи только корректный JSON массив в ответе, без пояснений и комментариев. Убедись, что все исходные поля каждого объекта сохранены в выходном JSON.
"""
STAGE_4_RAG_TEXT_RESPONSE_SCHEMA = {
    "type": "array",
    "items": {
        "type": "object",
        "properties": {
            "pos": {"type": "string"},
            "name": {"type": "string"},
            "type": {"type": "string"},
            "code": {"type": "string"},
            "manufacturer": {"type": "string"},
            "measure": {"type": "string"},
            "quantity": {"type": "string"},
            "weight": {"type": "string"},
            "note": {"type": "string"},
            "article": {"type": "string"},
            "rag_text": {"type": "string"}
        },
        "required": ["pos", "name", "type", "code", "manufacturer", "measure", "quantity", "weight", "note", "article",
                     "rag_text"]
    }
}

# --- Этап 5: Детальное извлечение атрибутов ---
STAGE_5_DETAIL_ATTR_SYSTEM_INSTRUCTION = """
# Инструкция по Детальному Извлечению Атрибутов Товара

## Роль
Ты — система интеллектуального анализа текста, специализирующаяся на извлечении структурированных атрибутов из описаний оборудования и материалов для инженерных систем (канализация, отопление, водоснабжение и т.п.).

## Цель
Твоя задача — проанализировать предоставленный текстовый фрагмент (обычно это предварительно обработанное поле `rag_text` или комбинация `name` и `article` из предыдущих этапов) и извлечь из него максимально точные и полные значения для следующих атрибутов товара. Результат должен быть представлен в виде JSON-объекта.

---

## Входные Данные
Одиночная строка текста, описывающая товар. Например:
`"Фитинги 5656 Переходник с внутренней резьбой G3/4 для соединения с трубой диаметром 25 мм (5656) категория фитинги назначение соединение труб разных стандартов allies адаптер"`
или
`"труба ре-ха/evoh sdr 7.4 s 3.2 размер 16x2.2 материал pe-xa evoh назначение для систем водоснабжения/отопления категория трубы"`

---

## Выходные Данные
JSON-объект, содержащий один элемент в массиве "datatable", со следующими полями. Каждое поле должно быть заполнено на основе анализа входного текста. Если информация для какого-либо поля отсутствует во входном тексте, оставь значение этого поля пустой строкой `""`.

**Пример выходного JSON:**
```json
{
  "datatable": [
    {
      "artikul": "5656",
      "category": "фитинги",
      "sub_category": "переходники резьбовые",
      "description": "переходник с внутренней резьбой g3/4 для соединения с трубой ø25 мм. артикул производителя (5656). предназначен для стыковки элементов с метрической и дюймовой резьбой.",
      "material": "", // Если не указан явно, оставить пустым
      "type_extracted": "переходник",
      "connection_type": "резьбовое g3/4 внутренняя, для трубы ø25 мм",
      "size": "g3/4 x ø25 мм",
      "allies": "адаптер, соединитель",
      "function": "соединение труб разных стандартов, подключение к оборудованию"
    }
  ]
}
```

---

## Правила Извлечения и Стандартизации Атрибутов:

1.  **`artikul`**:
    * Извлеки артикул или код товара, если он явно указан. Часто он может быть в скобках, или содержать буквы и цифры.
    * Сохраняй исходный регистр.
    * Пример: `"5656"`, `"ABC-12345"`.

2.  **`category`**:
    * Определи общую категорию товара.
    * Ищи ключевые слова, указывающие на широкую область применения.
    * Примеры: `"фитинги"`, `"трубы"`, `"арматура запорная"`, `"насосы"`, `"радиаторы отопления"`, `"теплоизоляция"`, `"крепеж"`, `"КИПиА"`.
    * Приводи к нижнему регистру.

3.  **`sub_category`**:
    * Определи более узкую подкатегорию внутри `category`.
    * Примеры: для `category: "фитинги"` -> `"отводы"`, `"тройники"`, `"муфты"`, `"переходники резьбовые"`; для `category: "арматура запорная"` -> `"краны шаровые"`, `"задвижки клиновые"`, `"вентили"`.
    * Приводи к нижнему регистру.

4.  **`description`**:
    * Сформируй краткое, но емкое описание товара на русском языке.
    * Включи основные характеристики и особенности, которые не вошли в другие специализированные поля, но важны для понимания сути товара.
    * Описание должно быть связным текстом, а не просто набором ключевых слов.
    * Избегай дублирования информации, уже представленной в других полях (например, точный размер или материал, если они есть в `size` и `material`).
    * Приводи к нижнему регистру.

5.  **`material`**:
    * Определи основной материал или материалы, из которых изготовлено изделие.
    * Примеры: `"латунь"`, `"сталь"`, `"сталь нержавеющая"`, `"чугун"`, `"полипропилен"`, `"PPR"`, `"медь"`, `"PE-Xa/EVOH"`, `"сшитый полиэтилен"`, `"бронза"`, `"ПВХ"`.
    * Если материалов несколько, перечисли их через запятую (например, `"сталь, резина"`).
    * Аббревиатуры материалов (PPR, PE-Xa) сохраняй в исходном виде или общепринятом написании. Остальное приводи к нижнему регистру.

6.  **`type_extracted`** (в схеме ответа это поле называется `type`):
    * Определи конкретный тип или вид изделия. Это основное наименование товара.
    * Примеры: `"переходник"`, `"кран шаровой"`, `"труба раструбная"`, `"радиатор секционный"`, `"насос циркуляционный"`, `"отвод 90 градусов"`, `"термостатический элемент"`, `"фильтр сетчатый"`.
    * Приводи к нижнему регистру.

7.  **`connection_type`**:
    * Определи тип(ы) присоединения изделия к системе.
    * Примеры: `"резьбовое"`, `"сварное"`, `"под приварку"`, `"раструбное"`, `"под пайку"`, `"фланцевое"`, `"компрессионное"`, `"пресс-соединение"`, `"цанговое"`.
    * Если возможно, уточни характеристики соединения:
        * Для резьбовых: направление резьбы (внутренняя/наружная - ВР/НР, ВН/НН), стандарт (G, R, Rp, Rc). Например: `"резьбовое g1/2 нр"`, `"резьбовое g3/4 вр/вр"`.
        * Для сварных/паечных/раструбных: диаметр присоединяемой трубы. Например: `"под сварку ø32 мм"`, `"раструбное ø50 мм"`.
        * Для фланцевых: условный проход (DN) и давление (PN). Например: `"фланцевое DN50 PN16"`.
    * Если типов несколько, перечисли их через запятую.
    * Приводи к нижнему регистру, сохраняя обозначения типа "G1/2", "НР", "ВР".

8.  **`size`**:
    * Извлеки и стандартизируй все ключевые размеры изделия.
    * Это могут быть: диаметры (условный проход DN, наружный диаметр, внутренний диаметр), длина, ширина, высота, толщина стенки, межосевое расстояние, резьбовые размеры (например, 1/2", 3/4", M10), количество секций и т.п.
    * Используй стандартизированные символы: `ø` для диаметра, `x` для разделения габаритов (например, `100x50x200 мм`).
    * Преобразуй дюймовые дроби в десятичные представления или сохраняй в виде "1/2 дюйма". Например: `1/2"` -> `"0.5 дюйма"` или `"1/2 дюйма"`.
    * Включай единицы измерения, если они есть в исходном тексте (`мм`, `см`, `м`, `дюйм`).
    * Если размеров несколько, перечисли их через запятую или используя `x` для габаритов. Например: `"ø25 мм x g3/4"`, `"DN15 (1/2 дюйма)"`, `"1000x500x50 мм"`, `"16x2.2 мм"`.
    * Включай также технические параметры, связанные с размерами, такие как SDR (Standard Dimension Ratio), PN (номинальное давление, если оно связано с размером фитинга/трубы), S-серия (для труб). Например: `"sdr 11"`, `"pn 10"`.
    * Приводи к нижнему регистру, сохраняя числовые значения и общепринятые обозначения (DN, PN, SDR).

9.  **`allies`**:
    * Перечисли через запятую подходящие синонимы, общепринятые альтернативные наименования или близкие по смыслу термины для данного `type_extracted` товара. Это поможет в дальнейшем поиске и сопоставлении.
    * Примеры: для `type_extracted: "отвод"` -> `"колено"`; для `type_extracted: "термостатический элемент"` -> `"термоголовка, терморегулятор"`; для `type_extracted: "кран шаровой"` -> `"вентиль шаровой"`; для `type_extracted: "переходник"` -> `"адаптер, редукция, ниппель переходной"`.
    * Приводи к нижнему регистру.

10. **`function`**:
    * Опиши основное функциональное назначение товара или область его применения.
    * Примеры: `"соединение труб разного диаметра"`, `"регулирование потока теплоносителя"`, `"перекрытие потока рабочей среды"`, `"изменение направления трубопровода на 90 градусов"`, `"транспортировка холодной и горячей воды"`, `"отопление жилых и общественных зданий"`, `"защита системы от избыточного давления"`, `"фильтрация механических примесей"`.
    * Приводи к нижнему регистру.

---

## Общие Требования к Форматированию:
* Все извлеченные строковые значения (кроме специально оговоренных случаев, таких как `artikul` или стандартные аббревиатуры типа PN, DN, SDR, G1/2, PE-Xa) должны быть приведены к **нижнему регистру**.
* Удали лишние пробелы в начале и конце строк, а также множественные пробелы между словами (оставляй только одиночные).
* Старайся извлекать информацию максимально полно, но без домысливания того, чего нет во входном тексте. Если какой-то атрибут однозначно не определяется из текста, оставь его значение пустым.
* Выходной JSON должен строго соответствовать указанной структуре и содержать массив `datatable` с одним объектом.
"""

STAGE_5_DETAIL_ATTR_RESPONSE_SCHEMA = {
    "type": "object", "properties": {"datatable": {"type": "array", "items": {
        "type": "object", "properties": {
            "artikul": {"type": "string"}, "category": {"type": "string"}, "sub_category": {"type": "string"},
            "description": {"type": "string"}, "material": {"type": "string"},
            "type_extracted": {"type": "string"}, # Это поле в инструкции называется type_extracted, но в схеме type
            "connection_type": {"type": "string"}, "size": {"type": "string"},
            "allies": {"type": "string"}, "function": {"type": "string"}
        },
        "required": ["artikul", "category", "sub_category", "description", "material", "type_extracted",
                     "connection_type",
                     "size", "allies", "function"]
    }}}, "required": ["datatable"]
}

# --- Этап 6: Сопоставление артикулов и заполнение Artikul_fact ---
STAGE_6_ARTICLE_MATCHING_SYSTEM_INSTRUCTION = """Цель: Сопоставить каждую позицию из данных, извлеченных из документа (далее "Позиция строки"), с соответствующим артикулом в справочнике (далее "Запись справочника") и определить значение для поля Artikul_fact в Позиции строки на основе этого сопоставления.

Источники данных:
1.  Позиция строки: JSON-объект, представляющий информацию о продукте с полями: `pos`, `name`, `type_original` (исходный тип), `code`, `manufacturer`, `measure`, `quantity`, `weight`, `note`, `article` (сформированный на Этапе 3), `rag_text` (сформированный на Этапе 4), `artikul` (извлеченный на Этапе 5), `category`, `sub_category`, `description`, `type_extracted` (извлеченный тип на Этапе 5), `connection_type`, `size`, `allies`, `function`. Поле `Artikul_fact` в этом объекте изначально пустое и его нужно заполнить.
2.  Справочник артикулов: JSON-массив, где каждая "Запись справочника" - это JSON-объект с информацией о продукте с полями: `artikul` (это эталонный артикул, который нужно присвоить), `category`, `description`, `size`, `type`, `connection_type`, `function`, `allies`, `material`.

Процесс сопоставления для ОДНОЙ Позиции строки:
1.  Анализ Позиции строки: Внимательно изучи все доступные поля Позиции строки, особенно `name`, `rag_text`, `type_extracted`, `size`, `connection_type`, `category`, `description`, `function`, `allies`, `article` (сформированный на Этапе 3). Эти поля содержат характеристики продукта, извлеченные из исходного документа.
2.  Поиск потенциальных совпадений в Справочнике артикулов: Для текущей Позиции строки просмотри ВСЕ Записи справочника. Ищи Записи справочника, которые максимально соответствуют характеристикам Позиции строки.
    * Ключевые поля для сравнения:
        * `type_extracted` (Позиция строки) vs `type` (Запись справочника)
        * `size` (Позиция строки) vs `size` (Запись справочника) - учитывай эквивалентность (например, DN15 = 1/2" = ø15мм)
        * `category` (Позиция строки) vs `category` (Запись справочника)
        * `connection_type` (Позиция строки) vs `connection_type` (Запись справочника) - это КРИТИЧЕСКИ ВАЖНОЕ поле.
        * `function` (Позиция строки) vs `function` (Запись справочника)
        * `allies` (Позиция строки) vs `allies` (Запись справочника)
        * Ключевые слова и фразы из `description`, `rag_text`, `name` (Позиция строки) vs `description` (Запись справочника).
3.  Оценка релевантности совпадений: Для каждой найденной потенциальной Записи справочника оцени степень соответствия Позиции строки.
    * **Типы соединений и системы, на которые ОБРАЩАТЬ ОСОБОЕ ВНИМАНИЕ:** "Аксиальное прессование", "Пресс-соединение", "Резьбовое", "Сварное", "Для трубы" (часто с указанием диаметра и/или типа трубы, например "для трубы PE-Xa", "для стальной трубы"), а также категории систем, если они упоминаются, например, "Аксиальная система", "Система LITE", "Приборы учета".
    * **Правила сопоставления типов соединений (примеры):**
        * Если в Позиции строки указано "натяжное" или "Пресс соединение", а в Записи справочника "Аксиальное прессование" -> это СЧИТАЕТСЯ СОВПАДЕНИЕМ по типу соединения.
    * **Уровни релевантности:**
        * **Высокая релевантность:** Практически полное совпадение по `type_extracted`/`type`, `size`. КРИТИЧЕСКИ ВАЖНО: должно быть четкое и однозначное совпадение по `connection_type` или по принадлежности к специфической системе (если указано). Пример: Позиция строки "надвижная гильза для пресс-фитингов 16" (где type_extracted="гильза надвижная", size="16", connection_type="пресс-фитинг/аксиальное") должна уверенно сопоставиться с Записью справочника "Монтажная гильза для систем LITE (аксиальное прессование) 16 мм. Артикул: 40105." (type="монтажная гильза", size="16 мм", connection_type="аксиальное прессование").
        * **Средняя релевантность:** Есть совпадение по `type_extracted`/`type` и/или `size`, НО есть неоднозначность или отсутствие явной информации по `connection_type`/системе в Позиции строки, в то время как в Справочнике артикулов есть несколько похожих продуктов с разными `connection_type` или для разных систем. Например, если Позиция строки "тройник ø20", а в справочнике есть "тройник аксиальный ø20" и "тройник резьбовой ø20".
        * **Низкая/Нулевая релевантность:** Отсутствие существенных совпадений по ключевым полям (тип, размер), или явное несоответствие по `connection_type`/системе.
4.  Принятие решения по заполнению `Artikul_fact` для Позиции строки:
    * **Случай 1 (Однозначное высокое совпадение):** Если найдена ОДНА Запись справочника с Высокой релевантностью, используй `artikul` из этой Записи справочника для заполнения поля `Artikul_fact`. `manual_check_needed` = `false`. `potential_artikuls` = [`artikul` этой записи].
    * **Случай 2 (Несколько высоких совпадений на один artikul):** Если найдено НЕСКОЛЬКО Записей справочника с Высокой релевантностью, но все они указывают на ОДИН И ТОТ ЖЕ `artikul` в Справочнике, используй этот `artikul`. `manual_check_needed` = `false`. `potential_artikuls` = [этот `artikul`].
    * **Случай 3 (Несколько высоких совпадений на разные artikul):** Если найдено НЕСКОЛЬКО Записей справочника с Высокой релевантностью, но они указывают на РАЗНЫЕ `artikul` в Справочнике, перечисли все эти `artikul` через запятую в поле `Artikul_fact`. `manual_check_needed` = `true`. `potential_artikuls` = [список этих разных `artikul`].
    * **Случай 4 (Только средняя релевантность):** Если найдены только совпадения со Средней релевантностью (одно или несколько), перечисли `artikul`(ы) из этих Записей справочника через запятую в поле `Artikul_fact`. `manual_check_needed` = `true`. `potential_artikuls` = [список `artikul`(ов) этих средних совпадений].
    * **Случай 5 (Нет достаточных совпадений):** Если не найдено совпадений с Высокой или Средней релевантностью, оставь `Artikul_fact` пустым. `manual_check_needed` = `true`. `potential_artikuls` = [].
    * В поле `matching_thoughts` кратко опиши логику принятия решения, особенно в случаях неоднозначности или если требуется ручная проверка.

Выходной формат: Предоставь JSON объект со следующими ключами: "artikul_fact" (строка, заполненная согласно правилам выше), "potential_artikuls" (массив строк), "manual_check_needed" (булево), "matching_thoughts" (строка с пояснениями).
"""

STAGE_6_ARTICLE_MATCHING_RESPONSE_SCHEMA = {
    "type": "object",
    "properties": {
        "artikul_fact": {"type": "string"},
        "potential_artikuls": {"type": "array", "items": {"type": "string"}},
        "manual_check_needed": {"type": "boolean"},
        "matching_thoughts": {"type": "string"}
    },
    "required": ["artikul_fact", "potential_artikuls", "manual_check_needed", "matching_thoughts"]
}

# --- Этап 7: Поиск страниц в PDF для каждого элемента ---
STAGE_7_PAGE_SEARCH_SYSTEM_INSTRUCTION = """
**Роль:** Ты - ИИ-ассистент, специализирующийся на поиске и локализации конкретных элементов спецификаций в многостраничных PDF-документах.
**Задача:** Для предоставленного элемента, описанного через набор его атрибутов, и полного PDF-документа, твоя задача - найти ВСЕ страницы (1-индексированные номера), на которых этот элемент упоминается или изображен.
**Контекст для поиска:**
- Таблицы спецификаций: Ищи строки, соответствующие элементу по позиции (`pos`), наименованию (`name`), типу (`type_original`, `type_extracted`), артикулу (`artikul`, `article`), производителю.
- Планы и схемы: Ищи графические обозначения или метки, которые могут соответствовать элементу (например, по `pos` или ключевым частям `name`, `size`). Учитывай, что на планах могут использоваться сокращения.
- Описательный текст: Ищи упоминания элемента в основном тексте документа.
**Важно:** Элемент может быть упомянут на нескольких страницах и в разных контекстах. Требуется найти все такие упоминания.
**Вывод:** Верни результат в строго заданном JSON формате.
"""

STAGE_7_USER_PROMPT_TEMPLATE = """
Проанализируй предоставленный PDF-документ (он был передан в секции `inline_data` в предыдущем сообщении сессии или будет передан там же) и найди все страницы, на которых упоминается или изображен следующий элемент.
Учитывай всю доступную информацию об элементе для точной идентификации.

**Информация об искомом элементе (извлеченный контекст):**
- Позиция (pos): "{pos}"
- Наименование (name): "{name}"
- Тип/Марка (type_original): "{type_original}"
- Код (code): "{code}"
- Производитель (manufacturer): "{manufacturer}"
- Ед. измерения (measure): "{measure}"
- Количество (quantity): "{quantity}"
- Сформированный Артикул (article из Этапа 3): "{article_e3}"
- Текст для RAG (rag_text из Этапа 4): "{rag_text_e4}"
- Извлеченный Артикул (artikul из Этапа 5): "{artikul_e5}"
- Категория (category): "{category}"
- Подкатегория (sub_category): "{sub_category}"
- Описание (description): "{description_e5}"
- Извлеченный тип (type_extracted): "{type_extracted_e5}"
- Тип соединения (connection_type): "{connection_type_e5}"
- Размер (size): "{size_e5}"
- Синонимы (allies): "{allies_e5}"
- Функция (function): "{function_e5}"
- Фактический Артикул (Artikul_fact из Этапа 6): "{Artikul_fact_e6}"

**Инструкции по поиску:**
1.  Используй всю вышеперечисленную информацию для поиска точных или контекстуально значимых упоминаний элемента.
2.  Проверь таблицы спецификаций, планы этажей, технологические схемы и основной текст документа.
3.  Верни УНИКАЛЬНЫЙ отсортированный список номеров страниц (1-индексированных), где найден элемент.

**Требуемый формат ответа (JSON):**
{{
  "item_name_ref": "{name_for_log}",
  "found_on_pages": [] // массив чисел, например [1, 5, 12]
}}

Если элемент не найден, верни пустой массив для "found_on_pages".
"""

STAGE_7_PAGE_SEARCH_RESPONSE_SCHEMA = {
    "type": "object",
    "properties": {
        "item_name_ref": {"type": "string"},
        "found_on_pages": {"type": "array", "items": {"type": "integer"}}
    },
    "required": ["item_name_ref", "found_on_pages"]
}


async def get_next_gemini_key() -> str:
    global gemini_key_index_counter, gemini_key_index_lock
    async with gemini_key_index_lock:
        key = GEMINI_API_KEYS[gemini_key_index_counter]
        gemini_key_index_counter = (gemini_key_index_counter + 1) % len(GEMINI_API_KEYS)
        return key


def load_reference_articles(file_path: str) -> List[Dict[str, Any]]:
    """Загружает и парсит справочник артикулов из TXT файла, содержащего JSON."""
    try:
        with open(file_path, "r", encoding="utf-8") as f:
            content = f.read()
            if not content.strip():
                print(f"Файл справочника артикулов {file_path} пуст.")
                return []
            reference_data = json.loads(content)
        if isinstance(reference_data, list):
            print(f"Успешно загружено {len(reference_data)} записей из справочника артикулов: {file_path}")
            return reference_data
        else:
            print(f"Ошибка: справочник артикулов в файле {file_path} не является JSON массивом.")
            return []
    except FileNotFoundError:
        print(f"Ошибка: Файл справочника артикулов не найден: {file_path}")
        return []
    except json.JSONDecodeError as e:
        print(f"Ошибка декодирования JSON в файле справочника артикулов {file_path}: {e}")
        return []
    except Exception as e:
        print(f"Неизвестная ошибка при загрузке справочника артикулов {file_path}: {e}")
        return []


# --- Функции для Этапа 1: Определение релевантных страниц ---
async def send_to_gemini_stage_1_page_id_async(session: aiohttp.ClientSession, api_key: str, base64_full_pdf: str,
                                               user_prompt_text: str, attempts: int = 3) -> List[int]:
    model_name = "gemini-2.5-flash-preview-04-17"
    url = f"https://generativelanguage.googleapis.com/v1beta/models/{model_name}:generateContent?key={api_key}"
    headers = {"Content-Type": "application/json"}
    payload = {
        "contents": [{
            "role": "user",
            "parts": [
                {"inline_data": {"mime_type": "application/pdf", "data": base64_full_pdf}},
                {"text": user_prompt_text}
            ]
        }],
        "system_instruction": {"parts": [{"text": WHOLE_DOC_SPEC_PAGE_IDENTIFICATION_SYSTEM_INSTRUCTION}]},
        "generationConfig": {"temperature": 0.1, "response_mime_type": "application/json",
                             "response_schema": WHOLE_DOC_SPEC_PAGE_IDENTIFICATION_RESPONSE_SCHEMA}
    }
    for attempt in range(attempts):
        try:
            print(
                f"Этап 1: Отправка ВСЕГО документа на идентификацию страниц (Попытка {attempt + 1}) к {model_name} с ключом ...{api_key[-4:]}")
            async with session.post(url, headers=headers, json=payload,
                                    timeout=aiohttp.ClientTimeout(total=300)) as response:
                if response.status == 200:
                    response_json = await response.json()
                    print(f"Этап 1: Успешный ответ на идентификацию страниц (весь документ) с ключом ...{api_key[-4:]}")
                    if "candidates" in response_json and response_json["candidates"]:
                        content = response_json["candidates"][0].get("content", {})
                        if "parts" in content and content["parts"]:
                            part_text = content["parts"][0].get("text")
                            if part_text:
                                try:
                                    parsed_json = json.loads(part_text)
                                    relevant_pages = parsed_json.get("relevant_pages", parsed_json.get("pages"))
                                    if relevant_pages is not None and isinstance(relevant_pages, list) and all(
                                            isinstance(p, int) and p > 0 for p in
                                            relevant_pages):  # Проверка, что номера > 0
                                        return sorted(list(set(relevant_pages)))  # Сортировка и удаление дубликатов
                                    else:
                                        print(
                                            f"Этап 1: Ошибка формата 'relevant_pages' или 'pages' (или номера <=0): {relevant_pages}");
                                        return []
                                except json.JSONDecodeError:
                                    print(f"Этап 1: Ошибка декодирования JSON: {part_text}")
                                    if part_text.strip().startswith('[') and part_text.strip().endswith(']'):
                                        try:
                                            evaluated_list = ast.literal_eval(part_text)
                                            if isinstance(evaluated_list, list) and all(
                                                    isinstance(p, int) and p > 0 for p in evaluated_list):
                                                print("Этап 1: Ответ успешно обработан как список Python.")
                                                return sorted(list(set(evaluated_list)))
                                            else:
                                                print(
                                                    f"Этап 1: ast.literal_eval не вернул список целых положительных чисел: {evaluated_list}")
                                        except (ValueError, SyntaxError) as e_ast:
                                            print(f"Этап 1: Ошибка ast.literal_eval: {e_ast}")
                                    return []
                    print(f"Этап 1: Некорректный формат ответа: {response_json}");
                    return []
                else:
                    error_text = await response.text()
                    print(f"Этап 1: Ошибка HTTP {response.status} (Попытка {attempt + 1}): {error_text}")
                    if response.status in {400, 401, 403, 404, 413}:
                        if response.status == 413: print("ОШИБКА Этап 1: Документ слишком большой.")
                        return []
                    if response.status == 429: await asyncio.sleep(20 * (attempt + 1)); continue
        except (aiohttp.ClientError, asyncio.TimeoutError) as e:
            print(f"Этап 1: Ошибка запроса (Попытка {attempt + 1}): {e}")
        except Exception as e:
            print(f"Этап 1: Неизвестная ошибка (Попытка {attempt + 1}): {e}\n{traceback.format_exc()}")
        if attempt < attempts - 1: await asyncio.sleep(10)
    print("Этап 1: Все попытки идентификации страниц провалились.");
    return []


async def identify_relevant_pages_stage_1_async(doc_path: str, output_folder: str, base64_full_pdf: str) -> List[int]:
    print("\n--- Этап 1: Определение страниц со спецификациями (весь документ) ---")
    global gemini_key_index_counter;
    gemini_key_index_counter = 0 # Сброс индекса ключа для этапа

    async with aiohttp.ClientSession() as session:
        selected_key = await get_next_gemini_key()
        relevant_page_numbers_1_based = await send_to_gemini_stage_1_page_id_async(session, selected_key,
                                                                                   base64_full_pdf, # Передаем уже закодированный PDF
                                                                                   STAGE_1_USER_PROMPT_TEXT)

    log_data = {"method": "whole_document_stage1", "identified_pages_1_indexed": relevant_page_numbers_1_based}
    log_path = os.path.join(output_folder, "stage_1_page_identification_log.json")
    try:
        with open(log_path, "w", encoding="utf-8") as f:
            json.dump(log_data, f, ensure_ascii=False, indent=4)
        print(f"Этап 1: Лог идентификации сохранен: {log_path}")
    except Exception as e:
        print(f"Этап 1: Ошибка сохранения лога: {e}")

    if relevant_page_numbers_1_based:
        print(
            f"Этап 1: Найдены релевантные страницы (1-инд. номера): {relevant_page_numbers_1_based} (Всего: {len(relevant_page_numbers_1_based)})")
    else:
        print("Этап 1: Релевантные страницы не найдены.")
    print("--- Завершение Этапа 1 ---")
    return relevant_page_numbers_1_based


# --- Функции для Этапа 2: Извлечение первичных данных ---
async def send_to_gemini_stage_2_extraction_async(session: aiohttp.ClientSession, api_key: str, base64_pdf_page: str,
                                                  page_index_0_based: int, attempts: int = 3) -> Dict[str, Any]:
    model_name = "gemini-2.5-flash-preview-04-17"
    url = f"https://generativelanguage.googleapis.com/v1beta/models/{model_name}:generateContent?key={api_key}"
    headers = {"Content-Type": "application/json"}
    payload = {
        "contents": [
            {"role": "user", "parts": [{"inline_data": {"mime_type": "application/pdf", "data": base64_pdf_page}}]}],
        "system_instruction": {"parts": [{"text": STAGE_2_EXTRACTION_SYSTEM_INSTRUCTION}]},
        "generationConfig": {"temperature": 0.1, "response_mime_type": "application/json"}
    }
    for attempt in range(attempts):
        try:
            print(
                f"Этап 2: Отправка стр. {page_index_0_based + 1} на извлечение (Попытка {attempt + 1}) к {model_name} с ключом ...{api_key[-4:]}")
            async with session.post(url, headers=headers, json=payload,
                                    timeout=aiohttp.ClientTimeout(total=120)) as response:
                if response.status == 200: return await response.json()
                error_text = await response.text()
                print(
                    f"Этап 2: Ошибка HTTP {response.status} (Стр. {page_index_0_based + 1}, Попытка {attempt + 1}): {error_text}")
                if response.status in {400, 401, 403, 404}: return {
                    "error": f"API Error: {response.status} - {error_text}"}
                if response.status == 429: await asyncio.sleep(10 * (attempt + 1)); continue
                # api_key = await get_next_gemini_key() # Не меняем ключ внутри цикла попыток для одного запроса
        except (aiohttp.ClientError, asyncio.TimeoutError) as e:
            print(f"Этап 2: Ошибка запроса (Стр. {page_index_0_based + 1}, Попытка {attempt + 1}): {e}")
        except Exception as e:
            print(f"Этап 2: Неизвестная ошибка (Стр. {page_index_0_based + 1}, Попытка {attempt + 1}): {e}\n{traceback.format_exc()}")
        if attempt == attempts - 1: return {
            "error": f"Этап 2: Все попытки для стр. {page_index_0_based + 1} провалились."}
        # api_key = await get_next_gemini_key() # Ключ меняется перед следующей попыткой, если текущий вызвал не 429
        await asyncio.sleep(5)
    return {"error": f"Этап 2: Все попытки для стр. {page_index_0_based + 1} провалились."}


def process_stage_2_gemini_response(response: Dict[str, Any]) -> List[Dict[str, str]]:
    try:
        if "error" in response: print(f"Этап 2: Gemini вернул ошибку: {response['error']}"); return []
        if "candidates" in response and response["candidates"]:
            content = response["candidates"][0].get("content", {})
            if "parts" in content and content["parts"]:
                part_text = content["parts"][0].get("text")
                if part_text:
                    try:
                        if isinstance(part_text, str) and part_text.startswith('"') and part_text.endswith('"'):
                            part_text = json.loads(part_text)
                        if isinstance(part_text, str):
                            try:
                                parsed_list = json.loads(part_text)
                            except json.JSONDecodeError:
                                print(f"Этап 2: Ошибка декодирования JSON (вторая попытка): {part_text[:200]}...")
                                return []
                        elif isinstance(part_text, list):
                            parsed_list = part_text
                        else:
                            print(f"Этап 2: Неожиданный тип part_text: {type(part_text)}")
                            return []

                        if isinstance(parsed_list, list):
                            processed_list = []
                            for item_dict in parsed_list:
                                if not isinstance(item_dict, dict): continue
                                processed_item = {}
                                # Сопоставление ключей из ответа Gemini с ожидаемыми ключами
                                key_map = {
                                    'поз': 'pos',
                                    'Наименование и техническая характеристика': 'name',
                                    'Тип, марка, обозначение документа, опросного листа': 'type_original',
                                    'Код продукции': 'code',
                                    'Поставщик': 'manufacturer', # Сопоставление "Поставщик" с "manufacturer"
                                    'Завод изготовитель': 'manufacturer', # Дополнительное сопоставление
                                    'Ед. измерения': 'measure',
                                    'Количество': 'quantity',
                                    'Масса 1 ед., кг': 'weight',
                                    'Примечание': 'note'
                                }
                                for raw_key, value in item_dict.items():
                                    found_match = False
                                    for pattern, target_key in key_map.items():
                                        if pattern.lower() in raw_key.lower():
                                            processed_item[target_key] = str(value) if value is not None else ""
                                            found_match = True
                                            break
                                    if not found_match: # Если ключ не стандартный, сохраняем как есть (или логируем)
                                        processed_item[raw_key] = str(value) if value is not None else ""


                                # Обеспечение наличия всех ожидаемых полей
                                for expected_key in ['pos', 'name', 'type_original', 'code', 'manufacturer',
                                                     'measure', 'quantity', 'weight', 'note', 'article',
                                                     'rag_text', 'artikul', 'category', 'sub_category',
                                                     'description', 'material', 'type_extracted', 'connection_type',
                                                     'size', 'allies', 'function', 'Artikul_fact',
                                                     'potential_artikuls', 'manual_check_needed',
                                                     'matching_thoughts', 'found_in_pdf_on_pages']: # Добавлено поле Этапа 7
                                    if expected_key not in processed_item:
                                        processed_item[expected_key] = ""
                                processed_list.append(processed_item)
                            return processed_list
                        else:
                            print(f"Этап 2: Ответ не список: {parsed_list}");
                            return []
                    except json.JSONDecodeError:
                        print(f"Этап 2: Ошибка декодирования JSON (первая попытка): {part_text[:200]}...");
                        return []
        print(f"Этап 2: Некорректный формат ответа: {response}");
        return []
    except Exception as e:
        print(f"Этап 2: Ошибка обработки ответа: {e}\n{traceback.format_exc()}");
        return []


async def process_stage_2_extraction_for_page(semaphore: asyncio.Semaphore, session: aiohttp.ClientSession,
                                              page_index_0_based: int, page_base64: str) -> Tuple[
    int, List[Dict[str, str]]]:
    async with semaphore:
        print(f"Этап 2: Начата обработка стр. {page_index_0_based + 1} (Извлечение)")
        start_time = time.time()
        selected_key = await get_next_gemini_key()
        gemini_response = await send_to_gemini_stage_2_extraction_async(session, selected_key, page_base64,
                                                                        page_index_0_based)
        datatable = process_stage_2_gemini_response(gemini_response)
        if "error" in gemini_response and not datatable:
            print(f"Этап 2: Ошибка Gemini для стр. {page_index_0_based + 1}: {gemini_response['error']}")
        elif datatable:
            print(f"Этап 2: Стр. {page_index_0_based + 1} извлечено {len(datatable)} строк.")
        else:
            print(f"Этап 2: Стр. {page_index_0_based + 1} нет результатов/ошибка парсинга.")
        print(f"Этап 2: Стр. {page_index_0_based + 1} обработана за {time.time() - start_time:.2f} сек.")
        return (page_index_0_based, datatable)


# --- Функции для Этапа 3: Заполнение 'article' ---
async def send_to_gemini_stage_3_article_async(session: aiohttp.ClientSession, api_key: str,
                                               page_data_for_gemini: Dict[str, Any], page_index_0_based: int,
                                               attempts: int = 3) -> Dict[str, Any]:
    model_name = "gemini-2.0-flash-lite"
    url = f"https://generativelanguage.googleapis.com/v1beta/models/{model_name}:generateContent?key={api_key}"
    headers = {"Content-Type": "application/json"}
    payload = {
        "contents": [{"role": "user", "parts": [{"text": json.dumps(page_data_for_gemini, ensure_ascii=False)}]}],
        "system_instruction": {"parts": [{"text": STAGE_3_ARTICLE_FILLING_SYSTEM_INSTRUCTION}]},
        "generationConfig": {"temperature": 0.0, "response_mime_type": "application/json",
                             "response_schema": STAGE_3_ARTICLE_FILLING_RESPONSE_SCHEMA}
    }
    current_api_key = api_key
    for attempt in range(attempts):
        try:
            print(
                f"Этап 3: Отправка стр. {page_index_0_based + 1} на 'article' (Попытка {attempt + 1}) к {model_name} с ключом ...{current_api_key[-4:]}")
            async with session.post(url, headers=headers, json=payload,
                                    timeout=aiohttp.ClientTimeout(total=120)) as response:
                if response.status == 200: return await response.json()
                error_text = await response.text()
                print(
                    f"Этап 3: Ошибка HTTP {response.status} (Стр. {page_index_0_based + 1}, Попытка {attempt + 1}): {error_text}")
                if response.status in {400, 401, 403, 404}: return {
                    "error": f"API Error: {response.status} - {error_text}"}
                if response.status == 429: await asyncio.sleep(10 * (attempt + 1)); continue
                # current_api_key = await get_next_gemini_key() # Не меняем ключ внутри цикла попыток
        except (aiohttp.ClientError, asyncio.TimeoutError) as e:
            print(f"Этап 3: Ошибка запроса (Стр. {page_index_0_based + 1}, Попытка {attempt + 1}): {e}")
        except Exception as e:
            print(f"Этап 3: Неизвестная ошибка (Стр. {page_index_0_based + 1}, Попытка {attempt + 1}): {e}\n{traceback.format_exc()}")
        if attempt == attempts - 1: return {
            "error": f"Этап 3: Все попытки для стр. {page_index_0_based + 1} провалились."}
        # current_api_key = await get_next_gemini_key(); # Ключ меняется перед следующей попыткой
        await asyncio.sleep(5)
    return {"error": f"Этап 3: Все попытки для стр. {page_index_0_based + 1} провалились."}


def process_stage_3_gemini_response(response: Dict[str, Any], original_page_data: List[Dict[str, str]]) -> List[
    Dict[str, str]]:
    try:
        if "error" in response:
            print(f"Этап 3: Gemini вернул ошибку: {response['error']}")
            for item in original_page_data: item.setdefault('article', "")
            return original_page_data

        if "candidates" in response and response["candidates"]:
            content = response["candidates"][0].get("content", {})
            if "parts" in content and content["parts"]:
                part_text = content["parts"][0].get("text")
                if part_text:
                    try:
                        if isinstance(part_text, str) and part_text.startswith('"') and part_text.endswith('"'):
                            part_text = json.loads(part_text)
                        if isinstance(part_text, str):
                            parsed_dict = json.loads(part_text)
                        elif isinstance(part_text, dict):
                            parsed_dict = part_text
                        else:
                            print(f"Этап 3: Неожиданный тип part_text: {type(part_text)}")
                            for item in original_page_data: item.setdefault('article', "")
                            return original_page_data

                        if isinstance(parsed_dict, dict) and "datatable" in parsed_dict and isinstance(
                                parsed_dict["datatable"], list):
                            updated_datatable_from_gemini = parsed_dict["datatable"]
                            final_list = []
                            if len(updated_datatable_from_gemini) == len(original_page_data):
                                for i, gemini_item in enumerate(updated_datatable_from_gemini):
                                    merged_item = original_page_data[i].copy() # Копируем исходный элемент
                                    # Обновляем только те поля, которые вернул Gemini для Этапа 3 (в основном 'article')
                                    if isinstance(gemini_item, dict):
                                         merged_item['article'] = str(gemini_item.get('article', merged_item.get('article', ''))) # Обновляем или сохраняем старое
                                    else: # Если gemini_item не словарь, оставляем 'article' как есть или пустым
                                        merged_item.setdefault('article', "")
                                    final_list.append(merged_item)
                                return final_list
                            else:
                                print(
                                    f"Этап 3: Длина ответа ({len(updated_datatable_from_gemini)}) не совпадает с входом ({len(original_page_data)}).")
                        else:
                            print(f"Этап 3: Ответ не 'datatable' список: {parsed_dict}");
                    except json.JSONDecodeError:
                        print(f"Этап 3: Ошибка декодирования JSON: {part_text[:200]}...");
        print(f"Этап 3: Некорректный формат ответа: {response}")
        for item in original_page_data: item.setdefault('article', "")
        return original_page_data
    except Exception as e:
        print(f"Этап 3: Ошибка обработки ответа: {e}\n{traceback.format_exc()}")
        for item in original_page_data: item.setdefault('article', "")
        return original_page_data


async def process_stage_3_article_filling_for_page(semaphore: asyncio.Semaphore, session: aiohttp.ClientSession,
                                                   page_index_0_based: int, datatable_for_page: List[Dict[str, str]],
                                                   previous_page_data: List[Dict[str, str]]) -> Tuple[
    int, List[Dict[str, str]]]:
    async with semaphore:
        print(f"Этап 3: Начата обработка стр. {page_index_0_based + 1} (Заполнение 'article')")
        start_time = time.time()
        datatable_for_gemini_s3 = []
        for item_s2 in datatable_for_page:
            item_copy_s3 = { # Передаем только те поля, которые ожидает модель на этом этапе
                "pos": item_s2.get("pos", ""),
                "name": item_s2.get("name", ""),
                "type": item_s2.get("type_original", ""), # 'type' в промпте Этапа 3 - это type_original
                "code": item_s2.get("code", ""),
                "manufacturer": item_s2.get("manufacturer", ""),
                "measure": item_s2.get("measure", ""),
                "quantity": item_s2.get("quantity", ""),
                "weight": item_s2.get("weight", ""),
                "note": item_s2.get("note", ""),
                "article": "" # Поле 'article' будет заполнено моделью
            }
            datatable_for_gemini_s3.append(item_copy_s3)

        previous_datatable_for_gemini_s3 = []
        for prev_item_s2 in previous_page_data:
            prev_item_copy_s3 = {
                "pos": prev_item_s2.get("pos", ""),
                "name": prev_item_s2.get("name", ""),
                "type": prev_item_s2.get("type_original", ""),
                "code": prev_item_s2.get("code", ""),
                "manufacturer": prev_item_s2.get("manufacturer", ""),
                "measure": prev_item_s2.get("measure", ""),
                "quantity": prev_item_s2.get("quantity", ""),
                "weight": prev_item_s2.get("weight", ""),
                "note": prev_item_s2.get("note", ""),
                "article": prev_item_s2.get("article", "") # 'article' из предыдущего этапа (если он уже был обработан)
            }
            previous_datatable_for_gemini_s3.append(prev_item_copy_s3)

        page_data_for_gemini = {"datatable": datatable_for_gemini_s3,
                                "previous_datatable": previous_datatable_for_gemini_s3}
        selected_key = await get_next_gemini_key()
        gemini_response = await send_to_gemini_stage_3_article_async(session, selected_key, page_data_for_gemini,
                                                                     page_index_0_based)
        # Передаем datatable_for_page (оригинальные данные с Этапа 2) для слияния
        updated_datatable_s3 = process_stage_3_gemini_response(gemini_response, datatable_for_page)


        if updated_datatable_s3 and any(item.get('article') for item in updated_datatable_s3):
            print(f"Этап 3: Стр. {page_index_0_based + 1} 'article' заполнен для {len(updated_datatable_s3)} строк.")
        elif "error" in gemini_response:
             print(f"Этап 3: Ошибка 'article' для стр. {page_index_0_based + 1}. Использованы данные Этапа 2 без изменений 'article'.")
        else:
            print(
                f"Этап 3: Стр. {page_index_0_based + 1} нет результатов 'article' или ошибка. Использованы данные Этапа 2 без изменений 'article'.");

        print(f"Этап 3: Стр. {page_index_0_based + 1} обработана за {time.time() - start_time:.2f} сек.")
        return (page_index_0_based, updated_datatable_s3)


# --- Функции для Этапа 4: Заполнение 'rag_text' ---
async def send_to_gemini_stage_4_rag_text_async(session: aiohttp.ClientSession, api_key: str,
                                                page_data: List[Dict[str, str]], page_index_0_based: int,
                                                attempts: int = 3) -> \
        Dict[str, Any]:
    model_name = "gemini-2.0-flash-lite"
    url = f"https://generativelanguage.googleapis.com/v1beta/models/{model_name}:generateContent?key={api_key}"
    headers = {"Content-Type": "application/json"}
    page_data_for_gemini_s4 = []
    for item_s3 in page_data: # Данные после Этапа 3
        item_copy_s4 = { # Передаем только те поля, которые ожидает модель на этом этапе
            "pos": item_s3.get("pos", ""),
            "name": item_s3.get("name", ""),
            "type": item_s3.get("type_original", ""), # 'type' в промпте Этапа 4 - это type_original
            "code": item_s3.get("code", ""),
            "manufacturer": item_s3.get("manufacturer", ""),
            "measure": item_s3.get("measure", ""),
            "quantity": item_s3.get("quantity", ""),
            "weight": item_s3.get("weight", ""),
            "note": item_s3.get("note", ""),
            "article": item_s3.get("article", ""), # 'article' после Этапа 3
            "rag_text": "" # Поле 'rag_text' будет заполнено моделью
        }
        page_data_for_gemini_s4.append(item_copy_s4)

    payload = {
        "contents": [{"role": "user", "parts": [{"text": json.dumps(page_data_for_gemini_s4, ensure_ascii=False)}]}],
        "system_instruction": {"parts": [{"text": STAGE_4_RAG_TEXT_SYSTEM_INSTRUCTION}]},
        "generationConfig": {"temperature": 0.0, "response_mime_type": "application/json",
                             "response_schema": STAGE_4_RAG_TEXT_RESPONSE_SCHEMA}
    }
    current_api_key = api_key
    for attempt in range(attempts):
        try:
            print(
                f"Этап 4: Отправка стр. {page_index_0_based + 1} на 'rag_text' (Попытка {attempt + 1}) к {model_name} с ключом ...{current_api_key[-4:]}")
            async with session.post(url, headers=headers, json=payload,
                                    timeout=aiohttp.ClientTimeout(total=180)) as response:
                if response.status == 200: return await response.json()
                error_text = await response.text()
                print(
                    f"Этап 4: Ошибка HTTP {response.status} (Стр. {page_index_0_based + 1}, Попытка {attempt + 1}): {error_text}")
                if response.status in {400, 401, 403, 404}: return {
                    "error": f"API Error: {response.status} - {error_text}"}
                if response.status == 429: await asyncio.sleep(10 * (attempt + 1)); continue
                # current_api_key = await get_next_gemini_key() # Не меняем ключ
        except (aiohttp.ClientError, asyncio.TimeoutError) as e:
            print(f"Этап 4: Ошибка запроса (Стр. {page_index_0_based + 1}, Попытка {attempt + 1}): {e}")
        except Exception as e:
            print(f"Этап 4: Неизвестная ошибка (Стр. {page_index_0_based + 1}, Попытка {attempt + 1}): {e}\n{traceback.format_exc()}")
        if attempt == attempts - 1: return {
            "error": f"Этап 4: Все попытки для стр. {page_index_0_based + 1} провалились."}
        # current_api_key = await get_next_gemini_key(); # Ключ меняется перед следующей попыткой
        await asyncio.sleep(5)
    return {"error": f"Этап 4: Все попытки для стр. {page_index_0_based + 1} провалились."}


def process_stage_4_gemini_response(response: Dict[str, Any], original_page_data: List[Dict[str, str]]) -> List[
    Dict[str, str]]:
    try:
        if "error" in response:
            print(f"Этап 4: Gemini вернул ошибку: {response['error']}")
            for item in original_page_data: item.setdefault('rag_text', "") # Гарантируем наличие поля
            return original_page_data

        if "candidates" in response and response["candidates"]:
            content = response["candidates"][0].get("content", {})
            if "parts" in content and content["parts"]:
                part_text = content["parts"][0].get("text")
                if part_text:
                    try:
                        if isinstance(part_text, str) and part_text.startswith('"') and part_text.endswith('"'):
                            part_text = json.loads(part_text)
                        if isinstance(part_text, str):
                            parsed_list_with_rag_text = json.loads(part_text)
                        elif isinstance(part_text, list):
                            parsed_list_with_rag_text = part_text
                        else:
                            print(f"Этап 4: Неожиданный тип part_text: {type(part_text)}")
                            for item in original_page_data: item.setdefault('rag_text', "")
                            return original_page_data

                        if isinstance(parsed_list_with_rag_text, list):
                            if len(parsed_list_with_rag_text) == len(original_page_data):
                                final_list_s4 = []
                                for i, gemini_item_s4 in enumerate(parsed_list_with_rag_text):
                                    merged_item_s4 = original_page_data[i].copy()
                                    if isinstance(gemini_item_s4, dict):
                                        merged_item_s4['rag_text'] = str(gemini_item_s4.get('rag_text', merged_item_s4.get('rag_text', '')))
                                    else:
                                        merged_item_s4.setdefault('rag_text', "")
                                    final_list_s4.append(merged_item_s4)
                                return final_list_s4
                            else:
                                print(
                                    f"Этап 4: Длина ответа ({len(parsed_list_with_rag_text)}) не совпадает с входом ({len(original_page_data)}).")
                        else:
                            print(f"Этап 4: Ответ не список: {parsed_list_with_rag_text}")
                    except json.JSONDecodeError:
                        print(f"Этап 4: Ошибка декодирования JSON: {part_text[:200]}...")
        print(f"Этап 4: Некорректный формат ответа: {response}")
        for item in original_page_data: item.setdefault('rag_text', "")
        return original_page_data
    except Exception as e:
        print(f"Этап 4: Ошибка обработки ответа: {e}\n{traceback.format_exc()}")
        for item in original_page_data: item.setdefault('rag_text', "")
        return original_page_data


async def process_stage_4_rag_text_filling_for_page(semaphore: asyncio.Semaphore, session: aiohttp.ClientSession,
                                                    page_index_0_based: int,
                                                    datatable_for_page_s3: List[Dict[str, str]]) -> Tuple[
    int, List[Dict[str, str]]]:
    async with semaphore:
        print(f"Этап 4: Начата обработка стр. {page_index_0_based + 1} (Заполнение 'rag_text')")
        start_time = time.time()
        if not datatable_for_page_s3:
            print(f"Этап 4: Стр. {page_index_0_based + 1} пропущена (нет данных с Этапа 3).")
            return (page_index_0_based, [])
        selected_key = await get_next_gemini_key()
        gemini_response = await send_to_gemini_stage_4_rag_text_async(session, selected_key, datatable_for_page_s3,
                                                                      page_index_0_based)
        updated_datatable_s4 = process_stage_4_gemini_response(gemini_response, datatable_for_page_s3)

        if updated_datatable_s4 and any(item.get('rag_text') for item in updated_datatable_s4):
            print(f"Этап 4: Стр. {page_index_0_based + 1} 'rag_text' обработан для {len(updated_datatable_s4)} строк.")
        elif "error" in gemini_response:
            print(f"Этап 4: Ошибка 'rag_text' для стр. {page_index_0_based + 1}. Использованы данные Этапа 3 без изменений 'rag_text'.")
        else:
            print(
                f"Этап 4: Стр. {page_index_0_based + 1} нет результатов 'rag_text'. Использованы данные Этапа 3 без изменений 'rag_text'.");

        print(f"Этап 4: Стр. {page_index_0_based + 1} обработана за {time.time() - start_time:.2f} сек.")
        return (page_index_0_based, updated_datatable_s4)


# --- Функции для Этапа 5: Детальное извлечение атрибутов ---
async def send_to_gemini_stage_5_detail_extraction_async(session: aiohttp.ClientSession, api_key: str,
                                                         item_data_text: str, item_name_for_log: str,
                                                         attempts: int = 3) -> Dict[str, Any]:
    model_name = "gemini-2.0-flash-lite"
    url = f"https://generativelanguage.googleapis.com/v1beta/models/{model_name}:generateContent?key={api_key}"
    headers = {"Content-Type": "application/json"}
    payload = {
        "contents": [{"role": "user", "parts": [{"text": item_data_text}]}],
        "system_instruction": {"parts": [{"text": STAGE_5_DETAIL_ATTR_SYSTEM_INSTRUCTION}]},
        "generationConfig": {"temperature": 0.0, "response_mime_type": "application/json",
                             "response_schema": STAGE_5_DETAIL_ATTR_RESPONSE_SCHEMA}
    }
    current_api_key = api_key
    for attempt in range(attempts):
        try:
            print(
                f"Этап 5: Отправка '{item_name_for_log[:30]}...' на детальное извлечение (Попытка {attempt + 1}) к {model_name} с ключом ...{current_api_key[-4:]}")
            async with session.post(url, headers=headers, json=payload,
                                    timeout=aiohttp.ClientTimeout(total=60)) as response:
                if response.status == 200: return await response.json()
                error_text = await response.text()
                print(
                    f"Этап 5: Ошибка HTTP {response.status} для '{item_name_for_log[:30]}...' (Попытка {attempt + 1}): {error_text}")
                if response.status in {400, 401, 403, 404}: return {
                    "error": f"API Error: {response.status} - {error_text}"}
                if response.status == 429: await asyncio.sleep(10 * (attempt + 1)); continue
                # current_api_key = await get_next_gemini_key() # Не меняем ключ
        except (aiohttp.ClientError, asyncio.TimeoutError) as e:
            print(f"Этап 5: Ошибка запроса для '{item_name_for_log[:30]}...' (Попытка {attempt + 1}): {e}")
        except Exception as e:
            print(f"Этап 5: Неизвестная ошибка для '{item_name_for_log[:30]}...' (Попытка {attempt + 1}): {e}\n{traceback.format_exc()}")
        if attempt == attempts - 1: return {
            "error": f"Этап 5: Все попытки для '{item_name_for_log[:30]}...' провалились."}
        # current_api_key = await get_next_gemini_key(); # Ключ меняется перед следующей попыткой
        await asyncio.sleep(5)
    return {"error": f"Этап 5: Все попытки для '{item_name_for_log[:30]}...' провалились."}


def process_stage_5_gemini_response(response: Dict[str, Any]) -> Union[Dict[str, str], None]:
    try:
        if "error" in response: print(f"Этап 5: Gemini вернул ошибку: {response['error']}"); return None
        if "candidates" in response and response["candidates"]:
            content = response["candidates"][0].get("content", {})
            if "parts" in content and content["parts"]:
                part_text = content["parts"][0].get("text")
                if part_text:
                    try:
                        if isinstance(part_text, str) and part_text.startswith('"') and part_text.endswith('"'):
                            part_text = json.loads(part_text)
                        if isinstance(part_text, str):
                            parsed_dict = json.loads(part_text)
                        elif isinstance(part_text, dict):
                            parsed_dict = part_text
                        else:
                            print(f"Этап 5: Неожиданный тип part_text: {type(part_text)}")
                            return None

                        if isinstance(parsed_dict, dict) and "datatable" in parsed_dict and \
                                isinstance(parsed_dict["datatable"], list) and len(parsed_dict["datatable"]) > 0:
                            extracted_attrs = parsed_dict["datatable"][0]
                            # ВАЖНО: переименовываем 'type' из ответа в 'type_extracted' для соответствия нашей структуре
                            if 'type' in extracted_attrs and 'type_extracted' not in extracted_attrs:
                                extracted_attrs['type_extracted'] = extracted_attrs.pop('type')
                            return {k: str(v) if v is not None else "" for k, v in extracted_attrs.items()}
                        else:
                            print(f"Этап 5: Ответ не 'datatable' список с элементом: {parsed_dict}");
                            return None
                    except json.JSONDecodeError:
                        print(f"Этап 5: Ошибка декодирования JSON: {part_text[:200]}...");
                        return None
        print(f"Этап 5: Некорректный формат ответа: {response}");
        return None
    except Exception as e:
        print(f"Этап 5: Ошибка обработки ответа: {e}\n{traceback.format_exc()}");
        return None


async def process_stage_5_detail_extraction_for_item(semaphore: asyncio.Semaphore, session: aiohttp.ClientSession,
                                                     item_data_s4: Dict[str, str]) -> Dict[str, str]:
    async with semaphore:
        item_name = item_data_s4.get('name', 'Без имени')
        text_for_analysis = item_data_s4.get('rag_text', '').strip()
        if not text_for_analysis: # Если rag_text пуст, используем name + article
            name_part = item_data_s4.get('name', '').strip()
            article_part = item_data_s4.get('article', '').strip() # article из Этапа 3
            text_for_analysis = f"{name_part} {article_part}".strip()

        updated_item_s5 = item_data_s4.copy()

        if not text_for_analysis:
            print(f"Этап 5: Пропуск '{item_name[:30]}...' (нет текста для анализа).")
        else:
            print(f"Этап 5: Начата обработка '{item_name[:30]}...' (Детальное извлечение)")
            start_time = time.time()
            selected_key = await get_next_gemini_key()
            gemini_response = await send_to_gemini_stage_5_detail_extraction_async(session, selected_key,
                                                                                   text_for_analysis, item_name)
            extracted_attributes_s5 = process_stage_5_gemini_response(gemini_response)
            if extracted_attributes_s5:
                updated_item_s5.update(extracted_attributes_s5)
                print(f"Этап 5: Элемент '{item_name[:30]}...' успешно дополнен атрибутами Этапа 5.")
            else:
                print(f"Этап 5: Не удалось извлечь атрибуты Этапа 5 для '{item_name[:30]}...'.")
            print(f"Этап 5: Элемент '{item_name[:30]}...' обработан за {time.time() - start_time:.2f} сек.")

        # Гарантируем наличие всех ключей из схемы Этапа 5
        stage_5_schema_keys = STAGE_5_DETAIL_ATTR_RESPONSE_SCHEMA["properties"]["datatable"]["items"]["properties"].keys()
        # Корректируем 'type' на 'type_extracted' при проверке ключей, если он так назван в схеме
        corrected_schema_keys = ['type_extracted' if key == 'type' else key for key in stage_5_schema_keys]

        for key_s5_schema in corrected_schema_keys:
            updated_item_s5.setdefault(key_s5_schema, "")
        return updated_item_s5


# --- Функции для Этапа 6: Сопоставление артикулов ---
async def send_to_gemini_stage_6_matching_async(session: aiohttp.ClientSession, api_key: str,
                                                item_to_match_json_str: str,
                                                reference_articles_json_str: str,
                                                item_name_for_log: str,
                                                attempts: int = 3) -> Dict[str, Any]:
    model_name = "gemini-2.0-flash-lite"
    url = f"https://generativelanguage.googleapis.com/v1beta/models/{model_name}:generateContent?key={api_key}"
    headers = {"Content-Type": "application/json"}

    prompt_text = f"""Проанализируй следующую "Позицию строки":
```json
{item_to_match_json_str}
```

И сопоставь ее с записями из следующего "Справочника артикулов":
```json
{reference_articles_json_str}
```
"""

    payload = {
        "contents": [{"role": "user", "parts": [{"text": prompt_text}]}],
        "system_instruction": {"parts": [{"text": STAGE_6_ARTICLE_MATCHING_SYSTEM_INSTRUCTION}]},
        "generationConfig": {"temperature": 0.0, "response_mime_type": "application/json",
                             "response_schema": STAGE_6_ARTICLE_MATCHING_RESPONSE_SCHEMA}
    }
    current_api_key = api_key
    for attempt in range(attempts):
        try:
            print(
                f"Этап 6: Отправка '{item_name_for_log[:30]}...' на сопоставление артикула (Попытка {attempt + 1}) к {model_name} с ключом ...{current_api_key[-4:]}")
            async with session.post(url, headers=headers, json=payload,
                                    timeout=aiohttp.ClientTimeout(total=180)) as response:
                if response.status == 200:
                    return await response.json()
                error_text = await response.text()
                print(
                    f"Этап 6: Ошибка HTTP {response.status} для '{item_name_for_log[:30]}...' (Попытка {attempt + 1}): {error_text}")
                if response.status in {400, 401, 403, 404}:
                    return {"error": f"API Error: {response.status} - {error_text}"}
                if response.status == 429:
                    await asyncio.sleep(15 * (attempt + 1))
                    continue
                # current_api_key = await get_next_gemini_key() # Не меняем ключ
        except (aiohttp.ClientError, asyncio.TimeoutError) as e:
            print(f"Этап 6: Ошибка запроса для '{item_name_for_log[:30]}...' (Попытка {attempt + 1}): {e}")
        except Exception as e:
            print(f"Этап 6: Неизвестная ошибка для '{item_name_for_log[:30]}...' (Попытка {attempt + 1}): {e}\n{traceback.format_exc()}")

        if attempt == attempts - 1:
            return {"error": f"Этап 6: Все попытки для '{item_name_for_log[:30]}...' провалились."}
        # current_api_key = await get_next_gemini_key() # Ключ меняется перед следующей попыткой
        await asyncio.sleep(10)
    return {"error": f"Этап 6: Все попытки для '{item_name_for_log[:30]}...' провалились."}


def process_stage_6_gemini_response(response: Dict[str, Any]) -> Union[Dict[str, Any], None]:
    try:
        if "error" in response:
            print(f"Этап 6: Gemini вернул ошибку: {response['error']}")
            return None
        if "candidates" in response and response["candidates"]:
            content = response["candidates"][0].get("content", {})
            if "parts" in content and content["parts"]:
                part_text = content["parts"][0].get("text")
                if part_text:
                    try:
                        if isinstance(part_text, str) and part_text.startswith('"') and part_text.endswith('"'):
                            part_text = json.loads(part_text)

                        if isinstance(part_text, str):
                            parsed_data = json.loads(part_text)
                        elif isinstance(part_text, dict):
                            parsed_data = part_text
                        else:
                            print(
                                f"Этап 6: Неожиданный тип part_text после возможного двойного декодирования: {type(part_text)}")
                            return None

                        if all(key in parsed_data for key in STAGE_6_ARTICLE_MATCHING_RESPONSE_SCHEMA["required"]):
                            return parsed_data
                        else:
                            print(f"Этап 6: Ответ не соответствует схеме: {parsed_data}")
                            # Попытка вернуть частичные данные, если основные ключи есть
                            return {
                                "artikul_fact": parsed_data.get("artikul_fact", ""),
                                "potential_artikuls": parsed_data.get("potential_artikuls", []),
                                "manual_check_needed": parsed_data.get("manual_check_needed", True),
                                "matching_thoughts": parsed_data.get("matching_thoughts", "Ответ не полностью соответствует схеме.")
                            }
                    except json.JSONDecodeError:
                        print(f"Этап 6: Ошибка декодирования JSON: {part_text[:200]}...")
                        return None
        print(f"Этап 6: Некорректный формат ответа от Gemini: {response}")
        return None
    except Exception as e:
        print(f"Этап 6: Ошибка обработки ответа Gemini: {e}\n{traceback.format_exc()}")
        return None


async def process_stage_6_matching_for_item(semaphore: asyncio.Semaphore, session: aiohttp.ClientSession,
                                            item_s5: Dict[str, str],
                                            reference_articles_str: str) -> Dict[str, str]:
    async with semaphore:
        item_name = item_s5.get('name', 'Без имени')
        updated_item_s6 = item_s5.copy()

        item_data_for_matching = {k: v for k, v in updated_item_s6.items() if k not in ["Artikul_fact", "potential_artikuls", "manual_check_needed", "matching_thoughts", "found_in_pdf_on_pages"]}
        item_data_for_matching["Artikul_fact"] = "" # Явно добавляем для промпта

        item_to_match_json_str = json.dumps(item_data_for_matching, ensure_ascii=False)

        print(f"Этап 6: Начата обработка сопоставления для '{item_name[:30]}...'")
        start_time = time.time()
        selected_key = await get_next_gemini_key()

        gemini_response_s6 = await send_to_gemini_stage_6_matching_async(
            session, selected_key, item_to_match_json_str, reference_articles_str, item_name
        )

        matching_results = process_stage_6_gemini_response(gemini_response_s6)

        if matching_results:
            updated_item_s6["Artikul_fact"] = matching_results.get("artikul_fact", "")
            updated_item_s6["potential_artikuls"] = matching_results.get("potential_artikuls", [])
            updated_item_s6["manual_check_needed"] = matching_results.get("manual_check_needed", True)
            updated_item_s6["matching_thoughts"] = matching_results.get("matching_thoughts", "")
            print(
                f"Этап 6: Элемент '{item_name[:30]}...' успешно сопоставлен. Artikul_fact: {updated_item_s6['Artikul_fact']}")
        else:
            print(f"Этап 6: Не удалось сопоставить артикул для '{item_name[:30]}...'. Artikul_fact останется пустым.")
            updated_item_s6["Artikul_fact"] = ""
            updated_item_s6["potential_artikuls"] = []
            updated_item_s6["manual_check_needed"] = True
            updated_item_s6["matching_thoughts"] = "Ошибка сопоставления или нет данных от модели."

        print(f"Этап 6: Элемент '{item_name[:30]}...' обработан (сопоставление) за {time.time() - start_time:.2f} сек.")
        return updated_item_s6

# --- Функции для Этапа 7: Поиск страниц в PDF для каждого элемента ---
async def send_to_gemini_stage_7_page_search_async(
    session: aiohttp.ClientSession,
    api_key: str,
    base64_full_pdf: str,
    item_details_prompt_text: str,
    item_name_for_log: str,
    attempts: int = 3
) -> Dict[str, Any]:
    model_name = "gemini-2.0-flash-lite"
    url = f"https://generativelanguage.googleapis.com/v1beta/models/{model_name}:generateContent?key={api_key}"
    headers = {"Content-Type": "application/json"}

    payload = {
        "contents": [
            {
                "role": "user",
                "parts": [
                    {"inline_data": {"mime_type": "application/pdf", "data": base64_full_pdf}},
                    {"text": item_details_prompt_text}
                ]
            }
        ],
        "system_instruction": {"parts": [{"text": STAGE_7_PAGE_SEARCH_SYSTEM_INSTRUCTION}]},
        "generationConfig": {
            "temperature": 0.0,
            "response_mime_type": "application/json",
            "response_schema": STAGE_7_PAGE_SEARCH_RESPONSE_SCHEMA
        }
    }
    current_api_key = api_key
    for attempt in range(attempts):
        try:
            print(
                f"Этап 7: Отправка '{item_name_for_log[:30]}...' на поиск страниц (Попытка {attempt + 1}) к {model_name} с ключом ...{current_api_key[-4:]}")
            async with session.post(url, headers=headers, json=payload,
                                    timeout=aiohttp.ClientTimeout(total=300)) as response:
                if response.status == 200:
                    return await response.json()
                error_text = await response.text()
                print(
                    f"Этап 7: Ошибка HTTP {response.status} для '{item_name_for_log[:30]}...' (Попытка {attempt + 1}): {error_text}")
                if response.status in {400, 401, 403, 404, 413}:
                    if response.status == 413: print(f"ОШИБКА Этап 7: PDF-документ или запрос слишком большой для '{item_name_for_log[:30]}...'.")
                    return {"error": f"API Error: {response.status} - {error_text}"}
                if response.status == 429:
                    await asyncio.sleep(20 * (attempt + 1))
                    continue
                # current_api_key = await get_next_gemini_key() # Не меняем ключ
        except (aiohttp.ClientError, asyncio.TimeoutError) as e:
            print(f"Этап 7: Ошибка запроса для '{item_name_for_log[:30]}...' (Попытка {attempt + 1}): {e}")
        except Exception as e:
            print(f"Этап 7: Неизвестная ошибка для '{item_name_for_log[:30]}...' (Попытка {attempt + 1}): {e}\n{traceback.format_exc()}")

        if attempt == attempts - 1:
            return {"error": f"Этап 7: Все попытки для '{item_name_for_log[:30]}...' провалились."}
        # current_api_key = await get_next_gemini_key() # Ключ меняется перед следующей попыткой
        await asyncio.sleep(10)
    return {"error": f"Этап 7: Все попытки для '{item_name_for_log[:30]}...' провалились."}

def process_stage_7_gemini_response(response: Dict[str, Any], item_name_ref_expected: str) -> List[int]:
    try:
        if "error" in response:
            print(f"Этап 7: Gemini вернул ошибку для '{item_name_ref_expected[:30]}...': {response['error']}")
            return []
        if "candidates" in response and response["candidates"]:
            content = response["candidates"][0].get("content", {})
            if "parts" in content and content["parts"]:
                part_text = content["parts"][0].get("text")
                if part_text:
                    try:
                        parsed_data = json.loads(part_text)
                        if isinstance(parsed_data, dict) and \
                           parsed_data.get("item_name_ref") == item_name_ref_expected and \
                           "found_on_pages" in parsed_data and \
                           isinstance(parsed_data["found_on_pages"], list):
                            pages = [p for p in parsed_data["found_on_pages"] if isinstance(p, int) and p > 0]
                            return sorted(list(set(pages)))
                        else:
                            print(f"Этап 7: Ответ не соответствует схеме или item_name_ref не совпал для '{item_name_ref_expected[:30]}...': {parsed_data}")
                            return []
                    except json.JSONDecodeError:
                        print(f"Этап 7: Ошибка декодирования JSON для '{item_name_ref_expected[:30]}...': {part_text[:200]}...")
                        return []
        print(f"Этап 7: Некорректный формат ответа от Gemini для '{item_name_ref_expected[:30]}...': {response}")
        return []
    except Exception as e:
        print(f"Этап 7: Ошибка обработки ответа Gemini для '{item_name_ref_expected[:30]}...': {e}\n{traceback.format_exc()}")
        return []

async def process_stage_7_page_search_for_item(
    semaphore: asyncio.Semaphore,
    session: aiohttp.ClientSession,
    base64_full_pdf: str,
    item_s6: Dict[str, str]
) -> Dict[str, Any]:
    async with semaphore:
        item_name = item_s6.get('name', 'Без имени')
        updated_item_s7 = item_s6.copy()

        prompt_details = {
            "pos": item_s6.get("pos", ""),
            "name": item_name,
            "type_original": item_s6.get("type_original", ""),
            "code": item_s6.get("code", ""),
            "manufacturer": item_s6.get("manufacturer", ""),
            "measure": item_s6.get("measure", ""),
            "quantity": item_s6.get("quantity", ""),
            "article_e3": item_s6.get("article", ""),
            "rag_text_e4": item_s6.get("rag_text", ""),
            "artikul_e5": item_s6.get("artikul", ""),
            "category": item_s6.get("category", ""),
            "sub_category": item_s6.get("sub_category", ""),
            "description_e5": item_s6.get("description", ""),
            "type_extracted_e5": item_s6.get("type_extracted", ""),
            "connection_type_e5": item_s6.get("connection_type", ""),
            "size_e5": item_s6.get("size", ""),
            "allies_e5": item_s6.get("allies", ""),
            "function_e5": item_s6.get("function", ""),
            "Artikul_fact_e6": item_s6.get("Artikul_fact", ""),
            "name_for_log": item_name
        }
        item_details_prompt_text = STAGE_7_USER_PROMPT_TEMPLATE.format(**prompt_details)

        print(f"Этап 7: Начата обработка поиска страниц для '{item_name[:30]}...'")
        start_time_s7_item = time.time() # Исправлено имя переменной
        selected_key = await get_next_gemini_key()

        gemini_response_s7 = await send_to_gemini_stage_7_page_search_async(
            session, selected_key, base64_full_pdf, item_details_prompt_text, item_name
        )

        found_pages = process_stage_7_gemini_response(gemini_response_s7, item_name)

        updated_item_s7["found_in_pdf_on_pages"] = found_pages
        if found_pages:
            print(f"Этап 7: Элемент '{item_name[:30]}...' найден на страницах: {found_pages}")
        else:
            print(f"Этап 7: Элемент '{item_name[:30]}...' не найден в PDF или произошла ошибка.")

        print(f"Этап 7: Элемент '{item_name[:30]}...' обработан (поиск страниц) за {time.time() - start_time_s7_item:.2f} сек.")
        return updated_item_s7

# --- Утилиты и основная функция ---
def save_to_xlsx_paged(processed_results_per_page: List[Tuple[int, List[Dict[str, str]]]], output_folder: str,
                       pdf_name: str):
    print("\nСохранение данных в XLSX файл (постранично)...")
    wb = Workbook()
    ws = wb.active
    ws.title = "Extracted Data"
    all_keys = set()
    # Сначала соберем все ключи из всех элементов всех страниц
    if processed_results_per_page:
        for _, page_items in processed_results_per_page:
            if page_items: # Убедимся, что есть элементы на странице
                for item in page_items:
                    if item and isinstance(item, dict): # Проверка, что item - это словарь и не пустой
                        all_keys.update(item.keys())

    preferred_order = [
        "pos", "name", "type_original", "article", "rag_text",
        "artikul", "Artikul_fact", "category", "sub_category", "type_extracted", "description",
        "material", "connection_type", "size", "allies", "function",
        "code", "manufacturer", "measure", "quantity", "weight", "note",
        "potential_artikuls", "manual_check_needed", "matching_thoughts",
        "found_in_pdf_on_pages"  # Новое поле для Этапа 7
    ]
    headers = [key for key in preferred_order if key in all_keys]
    # Добавляем остальные ключи, отсортированные, для предсказуемости
    headers.extend(sorted([key for key in all_keys if key not in preferred_order]))

    if not headers: # Если после всех этапов нет данных и ключей
        headers = ["Сообщение"]
        print("Нет данных для формирования заголовков XLSX.")

    ws.append(headers)

    for page_index_0_based, datatable_for_page in processed_results_per_page:
        ws.append([f"--- Страница документа (исходная) {page_index_0_based + 1} (0-инд: {page_index_0_based}) ---"] + [""] * (
            len(headers) - 1 if headers and headers != ["Сообщение"] else 0))
        if datatable_for_page:
            for row_data in datatable_for_page:
                if not row_data or not isinstance(row_data, dict): continue
                row_copy = row_data.copy()
                if "potential_artikuls" in row_copy and isinstance(row_copy["potential_artikuls"], list):
                    row_copy["potential_artikuls"] = ", ".join(map(str, row_copy["potential_artikuls"]))
                if "found_in_pdf_on_pages" in row_copy and isinstance(row_copy["found_in_pdf_on_pages"], list):
                    row_copy["found_in_pdf_on_pages"] = ", ".join(map(str, row_copy["found_in_pdf_on_pages"]))

                row_values = [str(row_copy.get(header, "")) for header in headers]
                ws.append(row_values)
        else:
            if headers == ["Сообщение"]:
                 ws.append(["(Нет извлеченных данных для этой страницы документа)"])
            else:
                ws.append(["(Нет извлеченных данных для этой страницы документа)"] + [""] * (len(headers) - 1 if headers else 0))
        ws.append([""] * len(headers) if headers and headers != ["Сообщение"] else [""]) # Пустая строка для разделения
        # print(f"Данные для исходной страницы PDF {page_index_0_based + 1} добавлены в XLSX.") # Это может быть слишком много логов

    output_file_xlsx = os.path.join(output_folder, f"{pdf_name}_final_data_page_by_page.xlsx")
    try:
        wb.save(output_file_xlsx)
        print(f"Данные успешно сохранены в: {output_file_xlsx}")
    except Exception as e:
        print(f"Ошибка при сохранении XLSX файла: {str(e)}\n{traceback.format_exc()}")


async def process_pdf_async(pdf_path: str):
    start_time_total = time.time()
    print(f"Общая обработка начата: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    base64_full_pdf_for_stages = "" # Инициализируем здесь
    try:
        pdf_path = os.path.normpath(pdf_path.strip('"\''))
        if not os.path.exists(pdf_path): print(f"Файл не найден: {pdf_path}"); return

        pdf_name = re.sub(r'[\\/*?:"<>|]', '', os.path.splitext(os.path.basename(pdf_path))[0]) or "Unknown"
        output_folder = os.path.join(os.path.dirname(pdf_path) or '.', pdf_name)
        os.makedirs(output_folder, exist_ok=True)

        try:
            with open(pdf_path, "rb") as f:
                pdf_bytes_full_doc = f.read()
            base64_full_pdf_for_stages = base64.b64encode(pdf_bytes_full_doc).decode("utf-8")
        except Exception as e:
            print(f"Критическая ошибка: Не удалось прочитать или закодировать PDF-файл {pdf_path}: {e}\n{traceback.format_exc()}")
            return

        # --- Этап 1: Определение релевантных страниц ---
        relevant_page_numbers_1_based = await identify_relevant_pages_stage_1_async(pdf_path, output_folder, base64_full_pdf_for_stages)
        if not relevant_page_numbers_1_based:
            print("Обработка остановлена: не найдено релевантных страниц на Этапе 1.")
            # Даже если страницы не найдены, создадим пустой XLSX с заголовками, если это нужно
            save_to_xlsx_paged([], output_folder, pdf_name)
            return

        # --- Подготовка данных для релевантных страниц ---
        print(
            f"\nПодготовка данных для {len(relevant_page_numbers_1_based)} релевантных страниц (конвертация в 0-индекс)...")
        pages_data_to_process = [] # Список кортежей (0-индекс страницы, base64 этой страницы)
        doc = fitz.open(pdf_path)
        for page_num_1_indexed in relevant_page_numbers_1_based:
            page_idx_0_indexed = page_num_1_indexed - 1
            if 0 <= page_idx_0_indexed < doc.page_count:
                single_page_doc = fitz.open()
                single_page_doc.insert_pdf(doc, from_page=page_idx_0_indexed, to_page=page_idx_0_indexed)
                pages_data_to_process.append(
                    (page_idx_0_indexed, base64.b64encode(single_page_doc.tobytes()).decode("utf-8"))) # Исправлено на .tobytes()
                single_page_doc.close()
            else:
                print(
                    f"Предупреждение: Запрошенный номер страницы {page_num_1_indexed} (0-индекс: {page_idx_0_indexed}) вне диапазона документа (0 до {doc.page_count - 1}). Страница пропущена.")
        doc.close()
        print(f"Подготовлено {len(pages_data_to_process)} релевантных страниц для Этапа 2.")
        if not pages_data_to_process:
            print("Нет страниц для дальнейшей обработки после фильтрации на Этапе 1.")
            save_to_xlsx_paged([], output_folder, pdf_name)
            return

        # --- Этап 2: Извлечение первичных данных ---
        stage_2_results_per_page: List[Tuple[int, List[Dict[str, str]]]] = []
        stage_2_errors = []
        stage_2_semaphore = asyncio.Semaphore(CONCURRENT_STAGE_2_EXTRACTION_LIMIT)
        global gemini_key_index_counter;
        gemini_key_index_counter = 0 # Сброс индекса ключа для этапа
        async with aiohttp.ClientSession() as session:
            tasks_s2 = [process_stage_2_extraction_for_page(stage_2_semaphore, session, p_idx_0_based, p_b64) for
                        p_idx_0_based, p_b64 in
                        pages_data_to_process]
            print(f"Этап 2: Запуск {len(tasks_s2)} задач извлечения...")
            results_s2 = await asyncio.gather(*tasks_s2, return_exceptions=True)

        temp_results_s2_dict = {}
        for res_s2 in results_s2:
            if isinstance(res_s2, tuple) and len(res_s2) == 2:
                temp_results_s2_dict[res_s2[0]] = res_s2[1]
            elif isinstance(res_s2, Exception):
                stage_2_errors.append(f"Этап 2 Ошибка: {res_s2}\n{traceback.format_exc()}")
            else:
                stage_2_errors.append(f"Этап 2 Неожиданный результат: {res_s2}")

        # Формируем stage_2_results_per_page в порядке исходных релевантных страниц
        for p_idx_0_based, _ in pages_data_to_process:
            stage_2_results_per_page.append((p_idx_0_based, temp_results_s2_dict.get(p_idx_0_based, [])))
        if stage_2_errors: print("\n--- Ошибки Этапа 2 ---"); [print(e) for e in stage_2_errors]

        # --- Этап 3: Заполнение 'article' ---
        stage_3_results_per_page: List[Tuple[int, List[Dict[str, str]]]] = []
        stage_3_errors = []
        gemini_key_index_counter = 0; # Сброс индекса ключа для этапа
        previous_datatable_stage3 = []
        temp_results_s3_dict = {}
        # Сортируем результаты Этапа 2 по номеру страницы для последовательной обработки Этапа 3
        sorted_stage_2_results_for_s3 = sorted(stage_2_results_per_page, key=lambda x: x[0])
        async with aiohttp.ClientSession() as session:
            for page_idx_0_based, data_for_page_s2 in sorted_stage_2_results_for_s3:
                if not data_for_page_s2: # Если на странице нет данных после этапа 2
                    temp_results_s3_dict[page_idx_0_based] = []
                    previous_datatable_stage3 = [] # Сбрасываем, так как была пустая страница
                    continue
                try:
                    idx_res_s3, updated_dt_s3 = await process_stage_3_article_filling_for_page(
                        asyncio.Semaphore(CONCURRENT_STAGE_3_ARTICLE_LIMIT), session, page_idx_0_based, data_for_page_s2,
                        previous_datatable_stage3)
                    temp_results_s3_dict[idx_res_s3] = updated_dt_s3
                    previous_datatable_stage3 = updated_dt_s3 # Обновляем для следующей страницы
                except Exception as e:
                    err_msg = f"Этап 3 Ошибка для стр. {page_idx_0_based + 1}: {e}\n{traceback.format_exc()}"
                    stage_3_errors.append(err_msg);
                    print(err_msg)
                    temp_results_s3_dict[page_idx_0_based] = data_for_page_s2 # Возвращаем данные Этапа 2
                    for item in temp_results_s3_dict[page_idx_0_based]: item.setdefault('article', "")
                    previous_datatable_stage3 = [] # Сбрасываем, так как была ошибка
        # Восстанавливаем порядок stage_3_results_per_page как у stage_2_results_per_page
        for p_idx_0_based, _ in stage_2_results_per_page:
            stage_3_results_per_page.append((p_idx_0_based, temp_results_s3_dict.get(p_idx_0_based, [])))
        if stage_3_errors: print("\n--- Ошибки Этапа 3 ---"); [print(e) for e in stage_3_errors]

        # --- Этап 4: Заполнение 'rag_text' ---
        stage_4_results_per_page: List[Tuple[int, List[Dict[str, str]]]] = []
        stage_4_errors = []
        stage_4_semaphore = asyncio.Semaphore(CONCURRENT_STAGE_4_RAG_TEXT_LIMIT)
        gemini_key_index_counter = 0 # Сброс индекса ключа для этапа
        temp_results_s4_dict = {}
        async with aiohttp.ClientSession() as session:
            tasks_s4 = []
            for page_idx_0_based, data_for_page_s3 in stage_3_results_per_page:
                if not data_for_page_s3: # Если нет данных с предыдущего этапа
                    temp_results_s4_dict[page_idx_0_based] = []
                    continue
                tasks_s4.append(
                    process_stage_4_rag_text_filling_for_page(stage_4_semaphore, session, page_idx_0_based,
                                                              data_for_page_s3))
            if tasks_s4:
                print(f"Этап 4: Запуск {len(tasks_s4)} задач 'rag_text'...")
                results_s4 = await asyncio.gather(*tasks_s4, return_exceptions=True)
                for res_s4 in results_s4:
                    if isinstance(res_s4, tuple) and len(res_s4) == 2:
                        temp_results_s4_dict[res_s4[0]] = res_s4[1]
                    elif isinstance(res_s4, Exception):
                        # Пытаемся извлечь page_idx из контекста ошибки, если это возможно
                        # Это сложная задача, так как gather возвращает только исключение
                        stage_4_errors.append(f"Этап 4 Ошибка в задаче: {res_s4}\n{traceback.format_exc()}")
                    else:
                        stage_4_errors.append(f"Этап 4 Неожиданный результат задачи: {res_s4}")
        # Собираем результаты Этапа 4, сохраняя порядок и обрабатывая пропущенные страницы
        for p_idx_0_based, data_s3 in stage_3_results_per_page:
            page_result_s4 = temp_results_s4_dict.get(p_idx_0_based)
            if page_result_s4 is not None:
                stage_4_results_per_page.append((p_idx_0_based, page_result_s4))
            elif not data_s3: # Если на этапе 3 не было данных
                stage_4_results_per_page.append((p_idx_0_based, []))
            else: # Если были данные на этапе 3, но этап 4 не вернул результат для этой страницы
                data_with_empty_rag = [dict(item, rag_text=item.get('rag_text', '')) for item in data_s3]
                stage_4_results_per_page.append((p_idx_0_based, data_with_empty_rag))
        if stage_4_errors: print("\n--- Ошибки Этапа 4 ---"); [print(e) for e in stage_4_errors]

        # --- Этап 5: Детальное извлечение атрибутов ---
        stage_5_results_per_page: List[Tuple[int, List[Dict[str, str]]]] = []
        stage_5_errors = []
        gemini_key_index_counter = 0 # Сброс индекса ключа для этапа
        temp_results_s5_dict = {} # Словарь для сбора результатов по страницам
        async with aiohttp.ClientSession() as session:
            all_items_for_s5_processing = [] # Плоский список всех элементов для обработки
            # [(page_idx, item_idx_on_page, item_data_s4), ...]
            for page_idx_0_based, items_on_page_s4 in stage_4_results_per_page:
                if not items_on_page_s4:
                    temp_results_s5_dict[page_idx_0_based] = [] # Сохраняем пустой список для этой страницы
                    continue
                # Инициализируем место для результатов этой страницы
                temp_results_s5_dict[page_idx_0_based] = [{} for _ in items_on_page_s4]
                for item_idx, item_s4 in enumerate(items_on_page_s4):
                    all_items_for_s5_processing.append(
                        {'page_idx': page_idx_0_based, 'item_idx_on_page': item_idx, 'data': item_s4})

            if all_items_for_s5_processing:
                stage_5_semaphore = asyncio.Semaphore(CONCURRENT_STAGE_5_DETAIL_ATTR_LIMIT)
                tasks_s5_flat = [
                    process_stage_5_detail_extraction_for_item(stage_5_semaphore, session, item_info['data'])
                    for item_info in all_items_for_s5_processing
                ]
                print(f"Этап 5: Запуск {len(tasks_s5_flat)} задач детального извлечения для всех элементов...")
                results_s5_flat = await asyncio.gather(*tasks_s5_flat, return_exceptions=True)

                for i, res_s5_item in enumerate(results_s5_flat):
                    original_item_info = all_items_for_s5_processing[i]
                    p_idx_0_based = original_item_info['page_idx']
                    item_idx_on_page = original_item_info['item_idx_on_page']
                    if isinstance(res_s5_item, dict):
                        temp_results_s5_dict[p_idx_0_based][item_idx_on_page] = res_s5_item
                    else: # Обработка исключений или неожиданных результатов
                        error_msg_s5 = f"Этап 5 Ошибка для элемента {item_idx_on_page} на стр. {p_idx_0_based + 1}: {res_s5_item}"
                        if isinstance(res_s5_item, Exception): error_msg_s5 += f"\n{traceback.format_exc()}"
                        stage_5_errors.append(error_msg_s5);
                        print(error_msg_s5)
                        # Возвращаем исходные данные с пустыми полями Этапа 5
                        fallback_item = original_item_info['data'].copy()
                        stage_5_schema_keys = STAGE_5_DETAIL_ATTR_RESPONSE_SCHEMA["properties"]["datatable"]["items"]["properties"].keys()
                        corrected_schema_keys_s5 = ['type_extracted' if key == 'type' else key for key in stage_5_schema_keys]
                        for key_s5_schema in corrected_schema_keys_s5: fallback_item.setdefault(key_s5_schema, "")
                        temp_results_s5_dict[p_idx_0_based][item_idx_on_page] = fallback_item
        # Собираем stage_5_results_per_page, сохраняя порядок страниц
        for p_idx_0_based, _ in stage_4_results_per_page:
            stage_5_results_per_page.append((p_idx_0_based, temp_results_s5_dict.get(p_idx_0_based, [])))
        if stage_5_errors: print("\n--- Ошибки Этапа 5 ---"); [print(e) for e in stage_5_errors]

        # --- Этап 6: Сопоставление артикулов ---
        print("\n--- Этап 6: Сопоставление артикулов ---")
        reference_articles = load_reference_articles(REFERENCE_ARTICLES_FILE_PATH)
        stage_6_results_per_page: List[Tuple[int, List[Dict[str, str]]]] = []
        stage_6_errors = []
        gemini_key_index_counter = 0 # Сброс индекса ключа для этапа
        temp_results_s6_dict = {}

        if not reference_articles:
            print("Этап 6: Справочник артикулов пуст или не загружен. Пропуск этапа сопоставления.")
            # Используем результаты Этапа 5 и добавляем пустые поля Этапа 6
            for p_idx, page_items_s5 in stage_5_results_per_page:
                page_result_s6 = []
                if page_items_s5:
                    for item_s5 in page_items_s5:
                        item_s6_fallback = item_s5.copy()
                        item_s6_fallback["Artikul_fact"] = ""
                        item_s6_fallback["potential_artikuls"] = []
                        item_s6_fallback["manual_check_needed"] = True
                        item_s6_fallback["matching_thoughts"] = "Справочник не загружен"
                        page_result_s6.append(item_s6_fallback)
                stage_6_results_per_page.append((p_idx, page_result_s6))
        else:
            reference_articles_str = json.dumps(reference_articles, ensure_ascii=False)
            async with aiohttp.ClientSession() as session:
                all_items_for_s6_processing = []
                for page_idx_0_based, items_on_page_s5 in stage_5_results_per_page:
                    if not items_on_page_s5:
                        temp_results_s6_dict[page_idx_0_based] = []
                        continue
                    temp_results_s6_dict[page_idx_0_based] = [{} for _ in items_on_page_s5]
                    for item_idx, item_s5 in enumerate(items_on_page_s5):
                        all_items_for_s6_processing.append(
                            {'page_idx': page_idx_0_based, 'item_idx_on_page': item_idx, 'data': item_s5})

                if all_items_for_s6_processing:
                    stage_6_semaphore = asyncio.Semaphore(CONCURRENT_STAGE_6_MATCHING_LIMIT)
                    tasks_s6_flat = [
                        process_stage_6_matching_for_item(stage_6_semaphore, session, item_info['data'],
                                                          reference_articles_str)
                        for item_info in all_items_for_s6_processing
                    ]
                    print(f"Этап 6: Запуск {len(tasks_s6_flat)} задач сопоставления артикулов...")
                    results_s6_flat = await asyncio.gather(*tasks_s6_flat, return_exceptions=True)

                    for i, res_s6_item in enumerate(results_s6_flat):
                        original_item_info = all_items_for_s6_processing[i]
                        p_idx_0_based = original_item_info['page_idx']
                        item_idx_on_page = original_item_info['item_idx_on_page']
                        if isinstance(res_s6_item, dict):
                            temp_results_s6_dict[p_idx_0_based][item_idx_on_page] = res_s6_item
                        else:
                            error_msg_s6 = f"Этап 6 Ошибка для элемента {item_idx_on_page} на стр. {p_idx_0_based + 1}: {res_s6_item}"
                            if isinstance(res_s6_item, Exception): error_msg_s6 += f"\n{traceback.format_exc()}"
                            stage_6_errors.append(error_msg_s6); print(error_msg_s6)
                            fallback_item = original_item_info['data'].copy()
                            fallback_item["Artikul_fact"] = ""
                            fallback_item["potential_artikuls"] = []
                            fallback_item["manual_check_needed"] = True
                            fallback_item["matching_thoughts"] = "Ошибка при вызове API сопоставления"
                            temp_results_s6_dict[p_idx_0_based][item_idx_on_page] = fallback_item
            for p_idx_0_based, _ in stage_5_results_per_page: # Собираем результаты в правильном порядке
                stage_6_results_per_page.append((p_idx_0_based, temp_results_s6_dict.get(p_idx_0_based, [])))
        if stage_6_errors: print("\n--- Ошибки Этапа 6 ---"); [print(e) for e in stage_6_errors]

        # --- Этап 7: Поиск страниц в PDF для каждого элемента ---
        print("\n--- Этап 7: Поиск страниц в PDF для каждого элемента ---")
        stage_7_results_items_flat: List[Dict[str, Any]] = []
        stage_7_errors = []
        gemini_key_index_counter = 0

        items_processed_up_to_stage6 = [item for _, page_items in stage_6_results_per_page for item in page_items if item]

        if not items_processed_up_to_stage6:
            print("Этап 7: Нет элементов для обработки после Этапа 6. Пропуск Этапа 7.")
            all_final_items_flat = [] # Итоговый список будет пуст
        elif not base64_full_pdf_for_stages:
            print("Этап 7: Отсутствует base64 полного PDF. Пропуск этапа. Данные Этапа 6 будут сохранены без информации о страницах.")
            all_final_items_flat = items_processed_up_to_stage6
            for item in all_final_items_flat: item.setdefault("found_in_pdf_on_pages", [])
        else:
            async with aiohttp.ClientSession() as session:
                stage_7_semaphore = asyncio.Semaphore(CONCURRENT_STAGE_7_PAGE_SEARCH_LIMIT)
                tasks_s7 = [
                    process_stage_7_page_search_for_item(
                        stage_7_semaphore, session, base64_full_pdf_for_stages, item_s6
                    ) for item_s6 in items_processed_up_to_stage6
                ]
                print(f"Этап 7: Запуск {len(tasks_s7)} задач поиска страниц...")
                results_s7_items_updated = await asyncio.gather(*tasks_s7, return_exceptions=True)

                for i, res_s7_item in enumerate(results_s7_items_updated):
                    original_item_s6 = items_processed_up_to_stage6[i] # Получаем исходный элемент
                    if isinstance(res_s7_item, dict) and "found_in_pdf_on_pages" in res_s7_item:
                        stage_7_results_items_flat.append(res_s7_item)
                    else:
                        err_msg = f"Этап 7 Ошибка в задаче для элемента '{original_item_s6.get('name', 'Без имени')}': {res_s7_item}"
                        if isinstance(res_s7_item, Exception): err_msg += f"\n{traceback.format_exc()}"
                        stage_7_errors.append(err_msg); print(err_msg)
                        # Добавляем исходный элемент с пустым полем found_in_pdf_on_pages
                        fallback_s7_item = original_item_s6.copy()
                        fallback_s7_item["found_in_pdf_on_pages"] = []
                        stage_7_results_items_flat.append(fallback_s7_item)
            all_final_items_flat = stage_7_results_items_flat

        if stage_7_errors: print("\n--- Ошибки Этапа 7 ---"); [print(e) for e in stage_7_errors]


        # --- Сбор и сохранение результатов ---
        print("\n--- Сбор итоговых данных (после Этапа 7) ---")

        if all_final_items_flat:
            output_json_final = os.path.join(output_folder, f"{pdf_name}_final_structured_data_flat.json")
            with open(output_json_final, "w", encoding="utf-8") as f:
                json.dump(all_final_items_flat, f, ensure_ascii=False, indent=4)
            print(
                f"\nФинальные результаты (плоский JSON) сохранены: {output_json_final} (Строк: {len(all_final_items_flat)})")

            items_for_embed_file = []
            for item_final in all_final_items_flat:
                transformed_item = {
                    "pos": item_final.get("pos", ""),
                    "name": item_final.get("name", ""),
                    "тип,_марка,_обозначение_документа,_опросного_листа": item_final.get("type_original", ""),
                    "code": item_final.get("code", ""),
                    "manufacturer": item_final.get("manufacturer", ""),
                    "measure": item_final.get("measure", ""),
                    "quantity": item_final.get("quantity", ""),
                    "масса_1_ед,_кг": item_final.get("weight", ""),
                    "note": item_final.get("note", ""),
                    "article": item_final.get("article", ""),
                    "rag_text": item_final.get("rag_text", ""),
                    "artikul": item_final.get("artikul", ""),
                    "category": item_final.get("category", ""),
                    "sub_category": item_final.get("sub_category", ""),
                    "description": item_final.get("description", ""),
                    "material": item_final.get("material", ""),
                    "type_extracted": item_final.get("type_extracted", ""),
                    "connection_type": item_final.get("connection_type", ""),
                    "size": item_final.get("size", ""),
                    "allies": item_final.get("allies", ""),
                    "function": item_final.get("function", ""),
                    "Artikul_fact": item_final.get("Artikul_fact", ""),
                    "potential_artikuls": ", ".join(map(str,item_final.get("potential_artikuls", []))),
                    "manual_check_needed": item_final.get("manual_check_needed", True),
                    "matching_thoughts": item_final.get("matching_thoughts", ""),
                    "found_in_pdf_on_pages": ", ".join(map(str, item_final.get("found_in_pdf_on_pages", []))), # Новое поле
                    # Поля из примера пользователя, которые могут дублироваться или быть специфичными
                    "type": item_final.get("type_original", ""), # Используем type_original для поля "type" как в примере пользователя
                    "weight": item_final.get("weight", ""), # Дублируем, как в примере
                }
                items_for_embed_file.append(transformed_item)

            output_json_embed = os.path.join(output_folder, "datatable_flat__to_embed.json")
            with open(output_json_embed, "w", encoding="utf-8") as f:
                json.dump(items_for_embed_file, f, ensure_ascii=False, indent=4)
            print(
                f"Данные для эмбеддинга (JSON с указанными ключами) сохранены: {output_json_embed} (Строк: {len(items_for_embed_file)})")
        else:
            print("\nНет финальных данных для сохранения в JSON.")

        # Сохраняем XLSX на основе данных, которые были до Этапа 7, но с добавлением информации о страницах, если она есть
        # Для этого нам нужен `stage_6_results_per_page`, но с обновленными элементами из `all_final_items_flat`
        # Это немного сложно, так как all_final_items_flat - плоский список.
        # Проще передать в save_to_xlsx_paged структуру, которая уже содержит обновленные элементы,
        # но сгруппированные по исходным страницам Этапа 1.
        # Поскольку all_final_items_flat уже содержит все данные, мы можем создать фиктивную постраничную структуру для XLSX.
        if all_final_items_flat:
            # Создаем фиктивную структуру "одна страница - все элементы" для XLSX, если он должен быть постраничным
            # Если XLSX должен быть плоским, то передаем [(0, all_final_items_flat)]
            # В текущей реализации save_to_xlsx_paged ожидает постраничную структуру.
            # Для простоты, если нам нужен плоский XLSX, его можно генерировать отдельно или модифицировать save_to_xlsx_paged
            # Пока оставим save_to_xlsx_paged как есть, но он будет показывать все элементы под "Страница 1" если передать так:
            save_to_xlsx_paged([(0, all_final_items_flat)], output_folder, pdf_name + "_flat_with_found_pages")
        else:
             print("\nНет данных для сохранения в XLSX.")


    except FileNotFoundError:
        print(f"Ошибка: Файл не найден: {pdf_path}")
    except Exception as e:
        print(f"Общая ошибка: {str(e)}\n{traceback.format_exc()}")
    finally:
        duration_total = time.time() - start_time_total
        print(
            f"\nОбщая обработка завершена: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} (Длительность: {duration_total:.2f} сек.)")


if __name__ == "__main__":
    # Устанавливаем кодировку для stdout и stderr в UTF-8, если это возможно
    if sys.stdout.encoding != 'utf-8' and hasattr(sys.stdout, 'reconfigure'):
        try:
            sys.stdout.reconfigure(encoding='utf-8')
            sys.stderr.reconfigure(encoding='utf-8')
            print("Кодировка вывода изменена на UTF-8.")
        except Exception as e_enc:
            print(f"Не удалось изменить кодировку вывода: {e_enc}")

    pdf_file_path = input("Введите путь к PDF-файлу: ")
    try:
        if sys.version_info >= (3, 7): # asyncio.run доступен с Python 3.7
            asyncio.run(process_pdf_async(pdf_file_path))
        else: # Для более старых версий Python
            loop = asyncio.get_event_loop()
            loop.run_until_complete(process_pdf_async(pdf_file_path))
    except Exception as err:
        print(f"Ошибка при запуске asyncio: {str(err)}\n{traceback.format_exc()}")
    finally:
        # Политика для Windows нужна только если стандартная вызывает проблемы.
        # Обычно это не требуется для aiohttp.
        # if sys.platform == "win32" and sys.version_info >= (3, 8):
        #     asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
        print("Завершение программы.")
